  <SECTION>
    <NAME>Concurrency: Time Is of the Essence</NAME>

    <SECTIONCONTENT/>

    <LABEL NAME="sec:time-is-of-the-essence"/>
    <INDEX>concurrency|(</INDEX>

    <TEXT>
      We<APOS/>ve seen the power of computational objects with local state as
      tools for modeling.  Yet, as Section<SPACE/><REF NAME="sec:costs-of-assignment"/>
      warned, this power extracts a price: the loss of referential
      transparency, giving rise to a thicket of questions about sameness and
      change, and the need to abandon the substitution model of evaluation in
      favor of the more intricate environment model.
    </TEXT>

    <TEXT>
      <INDEX>time<SUBINDEX>assignment and</SUBINDEX></INDEX>
      The central issue lurking beneath the complexity of state, sameness,
      and change is that by introducing assignment we are forced to admit
      <EM>time</EM> into our computational models.  Before we introduced
      assignment, all our programs were timeless, in the sense that any
      expression that has a value always has the same value.  In contrast,
      recall the example of modeling withdrawals from a bank account
      and returning the resulting balance,
      introduced at the beginning of
      Section<SPACE/><REF NAME="sec:local-state-variables"/>:

      <SNIPPET>
        <REQUIRES>withdraw</REQUIRES>
        <SCHEME>
          (withdraw 25)
        </SCHEME>
        <JAVASCRIPT>
          withdraw(25); // output: 75
        </JAVASCRIPT>
        <SCHEMEOUTPUT>
          75
        </SCHEMEOUTPUT>
      </SNIPPET>

      <SNIPPET>
        <REQUIRES>withdraw</REQUIRES>
        <REQUIRES>withdraw_example</REQUIRES>
        <SCHEME>
          (withdraw 25)
        </SCHEME>
        <JAVASCRIPT>
          withdraw(25); // output: 50
        </JAVASCRIPT>
        <SCHEMEOUTPUT>
          50
        </SCHEMEOUTPUT>
      </SNIPPET>
    </TEXT>

    <TEXT>
      Here successive evaluations of the same expression yield different
      values.  This behavior arises from the fact that the execution of
      assignment statements (in this case, assignments to the variable <SCHEMEINLINE>balance</SCHEMEINLINE>) delineates <EM>moments in time</EM> when values change.  The
      result of evaluating an expression depends not only on the expression
      itself, but also on whether the evaluation occurs before or after
      these moments.  Building models in terms of computational objects with
      local state forces us to confront time as an essential concept in
      programming.
    </TEXT>

    <TEXT>
      We can go further in structuring computational models to match our
      perception of the physical world.  Objects in the world do not change
      one at a time in sequence.  Rather we perceive them as acting <EM>
        concurrently</EM><EMDASH/>all at once.  So it is often natural to model systems
      as collections of computational processes that execute concurrently.
      Just as we can make our programs modular by organizing models in
      terms of objects with separate local state, it is often appropriate to
      divide computational models into parts that evolve separately and
      concurrently.  Even if the programs are to be executed on a sequential
      computer, the practice of writing programs as if they were to be
      executed concurrently forces the programmer to avoid inessential
      timing constraints and thus makes programs more modular.
    </TEXT>

    <TEXT>
      In addition to making programs more modular, concurrent computation
      can provide a speed advantage over sequential computation.  Sequential
      computers execute only one operation at a time, so the amount of time
      it takes to perform a task is proportional to the total number of
      operations performed.<FOOTNOTE>Most real processors actually execute a few
        operations at a time, following a strategy called 
        <INDEX>pipelining</INDEX>
        <EM>
          pipelining</EM>.  Although this technique greatly improves the effective
        utilization of the hardware, it is used only to speed up the execution
        of a sequential instruction stream, while retaining the behavior of
        the sequential program.</FOOTNOTE>
    </TEXT>

    <TEXT>
      However, if it is possible to decompose a problem into pieces that are
      relatively independent and need to communicate only rarely, it may be
      possible to allocate pieces to separate computing processors,
      producing a speed advantage proportional to the number of processors
      available.
    </TEXT>

    <TEXT>
      Unfortunately, the complexities introduced by assignment become even
      more problematic in the presence of concurrency.  The fact of
      concurrent execution, either because the world operates in parallel or
      because our computers do, entails additional complexity in our
      understanding of time.
    </TEXT>

    <!-- Subsection 1 : The Nature of Time in Concurrent Systems -->
    &subsection3.4.1;

    <!-- Subsection 2 : Mechanisms for Controlling Concurrency -->
    &subsection3.4.2;

  </SECTION>
