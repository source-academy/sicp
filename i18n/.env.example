API_KEY=

# Model to be used for translation
# ensure that selected assistant supports file search API
# models that are tried and shown to work includes: o3-mini, 4o and 4o mini
AI_MODEL=gpt-4.1-nano

# maximum number of characters to be sent for translation per batch, default: 3000
# smaller number of characters could lead to greater translation quality
# but worse continuity
MAX_LEN=5000

#Optional, only specify if calling alternative LLM provider
# Note: We require the Assistant API which only OpenAI provides as of 13 April 2025
AI_BASEURL=

# maximum number of concurent translations that are allowed
# if unspecified default to 5
MAX_TRANSLATION_NO=10

# Number of previous messages to be referred to in a thread for LLM Translation, if unspecified, default to 3
# Higher context size might lead to greater continuity in translation but higher cost and lower speed.
CONTEXT=3

# Number of token per query which when exceeded will log an error
# Formula to derive an adequate value: MAX_LEN * CONTEXT * k, where k is a constant
# Recommended k = 1.5
TOKEN_WARNING=7000