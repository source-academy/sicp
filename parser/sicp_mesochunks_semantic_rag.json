[
  {
    "chapter_file": "chapter1_chunks.json",
    "section": null,
    "subsection": "Building Abstractions with Procedures Functions",
    "chunk_id": "chapter1_chunks_Building_Abstractions_with_Procedures_Functions_1",
    "chunk_index": 1,
    "content": "We are about to study the idea of a computational process . data . program . People create programs to direct processes. In effect, we conjure the spirits of the computer with our spells. A computational process is indeed much like a sorcerer s idea of a spirit. It cannot be seen or touched. It is not composed of matter at all. However, it is very real. It can perform intellectual work. It can answer questions. It can affect the world by disbursing money at a bank or by controlling a robot arm in a factory. The programs we use to conjure processes are like a sorcerer s spells. They are carefully composed from symbolic expressions in arcane and esoteric programming languages\nA computational process, in a correctly working computer, executes programs precisely and accurately. Thus, like the sorcerer s apprentice, novice programmers must learn to understand and to anticipate the consequences of their conjuring. Even small errors (usually called bugs or glitches ) (usually called bugs ) in programs can have complex and unanticipated consequences. Fortunately, learning to program is considerably less dangerous than learning sorcery, because the spirits we deal with are conveniently contained in a secure way. Real-world programming, however, requires care, expertise, and wisdom. A small bug in a computer-aided design program, for example, can lead to the catastrophic collapse of an airplane or a dam or the self-destruction of an industrial robot.",
    "token_count": 287,
    "source_files": [
      "chapter1.xml"
    ]
  },
  {
    "chapter_file": "chapter1_chunks.json",
    "section": null,
    "subsection": "Building Abstractions with Procedures Functions",
    "chunk_id": "chapter1_chunks_Building_Abstractions_with_Procedures_Functions_2",
    "chunk_index": 2,
    "content": "Master software engineers have the ability to organize programs so that they can be reasonably sure that the resulting processes will perform the tasks intended. They can visualize the behavior of their systems in advance. They know how to structure programs so that unanticipated problems do not lead to catastrophic consequences, and when problems do arise, they can debug their programs. Well-designed computational systems, like well-designed automobiles or nuclear reactors, are designed in a modular manner, so that the parts can be constructed, replaced, and debugged separately. We need an appropriate language for describing processes, and we will use for this purpose the programming language Lisp. Just as our everyday thoughts are usually expressed in our natural language (such as English, Swedish, or German), and descriptions of quantitative phenomena are expressed with mathematical notations, our procedural thoughts will be expressed in Lisp. recursion equations , as a model for computation. The language was conceived by Recursive Functions of Symbolic Expressions and Their Computation by Machine (\nWe need an appropriate language for describing processes, and we will use for this purpose the programming language JavaScript. Just as our everyday thoughts are usually expressed in our natural language (such as English, Swedish, or Chinese), and descriptions of quantitative phenomena are expressed with mathematical notations, our procedural thoughts will be expressed in JavaScript. Mocha , which was later renamed to LiveScript , and finally to JavaScript. JavaScript is a trademark of Oracle Corporation. Despite its inception as a mathematical formalism, Lisp is a practical programming language.",
    "token_count": 298,
    "source_files": [
      "chapter1.xml"
    ]
  },
  {
    "chapter_file": "chapter1_chunks.json",
    "section": null,
    "subsection": "Building Abstractions with Procedures Functions",
    "chunk_id": "chapter1_chunks_Building_Abstractions_with_Procedures_Functions_3",
    "chunk_index": 3,
    "content": "A Lisp interpreter is a machine that carries out processes described in the Lisp language. The first Lisp interpreter was implemented by\nDespite its inception as a language for scripting the web, JavaScript interpreter is a machine that carries out processes described in the JavaScript language. Lisp was not the product of a concerted design effort. Instead, it evolved informally in an experimental manner in response to users needs and to pragmatic implementation considerations. Lisp s informal evolution has continued through the years, and the community of Lisp users has traditionally resisted attempts to promulgate any official definition of the language. This evolution, together with the flexibility and elegance of the initial conception, has enabled Lisp, which is the second oldest language in widespread use today (only\nJavaScript bears only superficial resemblance to the language Java, after which it was (eventually) named; both Java and JavaScript use the block structure of the language C. In contrast with Java and C, which usually employ compilation to lower-level languages, JavaScript programs were initially interpreted by web browsers. s Internet Explorer, whose JavaScript version is called JScript . The popularity of JavaScript for controlling web browsers gave rise to a standardization effort, culminating in ECMAScript . The and completed in June 1997 (\nBecause of its experimental character and its emphasis on symbol manipulation,\nThe practice of embedding JavaScript programs in web pages encouraged the developers of web browsers to implement JavaScript interpreters.",
    "token_count": 279,
    "source_files": [
      "chapter1.xml"
    ]
  },
  {
    "chapter_file": "chapter1_chunks.json",
    "section": null,
    "subsection": "Building Abstractions with Procedures Functions",
    "chunk_id": "chapter1_chunks_Building_Abstractions_with_Procedures_Functions_4",
    "chunk_index": 4,
    "content": "As these programs became more complex, the interpreters became more efficient in executing them, eventually using sophisticated implementation techniques such as Just-In-Time (JIT) compilation. The majority of JavaScript programs as of this writing (2021) are embedded in web pages and interpreted by browsers, but JavaScript is increasingly used as a general-purpose programming language, using systems such as Node.js. If Lisp is not a mainstream language, why are we using it as the framework for our discussion of programming? Because the language possesses procedures , can themselves be represented and manipulated as Lisp data. The importance of this is that there are powerful program-design techniques that rely on the ability to blur the traditional distinction between passive data and active processes. As we shall discover, Lisp s flexibility in handling procedures as data makes it one of the most convenient languages in existence for exploring these techniques. The ability to represent procedures as data also makes Lisp an excellent language for writing programs that must manipulate other programs as data, such as the interpreters and compilers that support computer languages. Above and beyond these considerations, programming in Lisp is great fun.",
    "token_count": 219,
    "source_files": [
      "chapter1.xml"
    ]
  },
  {
    "chapter_file": "chapter1_chunks.json",
    "section": "Building Abstractions with Procedures Functions",
    "subsection": "The Elements of Programming",
    "chunk_id": "chapter1_chunks_The_Elements_of_Programming_1",
    "chunk_index": 1,
    "content": "A powerful programming language is more than just a means for instructing a computer to perform tasks. The language also serves as a framework within which we organize our ideas about processes. Thus, when we describe a language, we should pay particular attention to the means that the language provides for combining simple ideas to form more complex ideas. Every powerful language has three mechanisms for accomplishing this: primitive expressions , cerned with, means of combination , by means of abstraction ,\nIn programming, we deal with two kinds of elements: and stuff that we want to manipulate, and procedures functions are descriptions of the rules for manipulating the data. Thus, any powerful programming language should be able to describe primitive data and primitive procedures functions and should have methods for combining and abstracting procedures functions and data. In this chapter we will deal only with simple procedures functions . procedures functions to manipulate compound data as well.",
    "token_count": 177,
    "source_files": [
      "section1.xml"
    ]
  },
  {
    "chapter_file": "chapter1_chunks.json",
    "section": "The Elements of Programming",
    "subsection": "Expressions",
    "chunk_id": "chapter1_chunks_Expressions_1",
    "chunk_index": 1,
    "content": "One easy way to get started at programming is to examine some typical interactions with an interpreter for the Scheme dialect of Lisp. JavaScript language. Imagine that you are sitting at a computer terminal. You type an expression , a statement , and the interpreter responds by displaying the result of its evaluating that expression. One kind of statement you might type is an expression statement, which consists of an expression followed by a semicolon. (More precisely, the expression that you type consists of the numerals that represent the number in base 10.) If you present Lisp with a number JavaScript with the program 486 486; the interpreter will respond by printing 486\nExpressions representing numbers may be combined with an + or * ) to form a compound expression that represents the application of the procedure to those numbers. For example, (+ 137 349) 486 (- 1000 334) 666 (* 5 99) 495 (/ 10 5) 2 (+ 2.7 10) 12.7",
    "token_count": 206,
    "source_files": [
      "subsection1.xml"
    ]
  },
  {
    "chapter_file": "chapter1_chunks.json",
    "section": "The Elements of Programming",
    "subsection": "Expressions",
    "chunk_id": "chapter1_chunks_Expressions_2",
    "chunk_index": 2,
    "content": "Expressions representing numbers may be combined with operators (such + * ) to form a 137 + 349; 486 1000 - 334; 666 5 * 99; 495 10 / 4; 2.5 2.7 + 10; 12.7\nExpressions such as these, formed by combinations . The leftmost element in the list is called the operator , and the other elements are called operands . The arguments that are the values of the operands. Expressions such as these, which contain other expressions as components, are called combinations . operator symbol in the middle, and operand expressions to the left and right of it, are called operator combinations . The convention of placing the operator to the left of the operands is known as prefix notation , and it may be somewhat confusing at first because it departs significantly from the customary mathematical convention. Prefix notation has several advantages, however. One of them is that it can accommodate (+ 21 35 12 7) 75 (* 25 4 12) 1200 No ambiguity can arise, because the operator is always the leftmost element and the entire combination is delimited by the parentheses.",
    "token_count": 242,
    "source_files": [
      "subsection1.xml"
    ]
  },
  {
    "chapter_file": "chapter1_chunks.json",
    "section": "The Elements of Programming",
    "subsection": "Expressions",
    "chunk_id": "chapter1_chunks_Expressions_3",
    "chunk_index": 3,
    "content": "A second advantage of prefix notation is that it extends in a straightforward way to allow combinations to be nested , that is, to have combinations whose elements are themselves combinations: (+ (* 3 5) (- 10 6)) 19\nThe convention of placing the operator between the operands is known as infix notation . It follows the mathematical notation that you are most likely familiar with from school and everyday life. As in mathematics, operator combinations can be nested , that is, they can have operands that (3 * 5) + (10 - 6); 19 As usual, 3 * 5 + 10 / 2; stands for (3 * 5) + (10 / 2); We say that * and / have higher precedence than + and - . Sequences of additions and subtractions are read from left to right, as are sequences of multiplications and divisions. Thus, -6 1 - 5 / 2 * 4 + 3; stands for (1 - ((5 / 2) * 4)) + 3; We say that the operators + , - , * and / are left-associative . There is no limit (in principle) to the depth of such nesting and to the overall complexity of the expressions that the Lisp interpreter can evaluate.",
    "token_count": 268,
    "source_files": [
      "subsection1.xml"
    ]
  },
  {
    "chapter_file": "chapter1_chunks.json",
    "section": "The Elements of Programming",
    "subsection": "Expressions",
    "chunk_id": "chapter1_chunks_Expressions_4",
    "chunk_index": 4,
    "content": "It is we humans who get confused by still relatively simple expressions such as (+ (* 3 (+ (* 2 4) (+ 3 5))) (+ (- 10 7) 6)) which the interpreter would readily evaluate to be 57. We can help ourselves by writing such an expression in the form (+ (* 3 (+ (* 2 4) (+ 3 5))) (+ (- 10 7) 6)) following a formatting convention known as pretty-printing , in which each long combination is written so that the operands are aligned vertically. The resulting\nThere is no limit (in principle) to the depth of such nesting and to the overall complexity of the expressions that the JavaScript interpreter can evaluate. It is we humans who might get confused by still relatively simple expressions such as 57 3 * 2 * (3 - 5 + 4) + 27 / 6 * 10; which the interpreter would readily evaluate to be 57. We can help ourselves by writing such an expression in the form 3 * 2 * (3 - 5 + 4) + 27 / 6 * 10; to visually separate the major components of the expression. Even with complex expressions, the interpreter always operates in the same basic cycle: It reads an expression from the terminal, a statement typed by the user, evaluates the expression, statement, and prints the result.",
    "token_count": 289,
    "source_files": [
      "subsection1.xml"
    ]
  },
  {
    "chapter_file": "chapter1_chunks.json",
    "section": "The Elements of Programming",
    "subsection": "Expressions",
    "chunk_id": "chapter1_chunks_Expressions_5",
    "chunk_index": 5,
    "content": "This mode of operation is often expressed by saying that the interpreter runs in a read-eval-print loop . read-evaluate-print loop . Observe in particular that it is not necessary to explicitly instruct the interpreter to print the value of the expression. statement.",
    "token_count": 51,
    "source_files": [
      "subsection1.xml"
    ]
  },
  {
    "chapter_file": "chapter2_chunks.json",
    "section": null,
    "subsection": "Building Abstractions with Data",
    "chunk_id": "chapter2_chunks_Building_Abstractions_with_Data_1",
    "chunk_index": 1,
    "content": "We concentrated in chapter on computational processes and on the role of procedures functions in program design. We saw how to use primitive data (numbers) and primitive operations (arithmetic operations), how to combine procedures functions to form compound procedures functions through composition, conditionals, and the use of parameters, and how to abstract procedures processes by using define . function declarations. We saw that a procedure function can be regarded as a pattern for the local evolution of a process, and we classified, reasoned about, and performed simple algorithmic analyses of some common patterns for processes as embodied in procedures. functions. We also saw that higher-order procedures functions enhance the power of our language by enabling us to manipulate, and thereby to reason in terms of, general methods of computation. This is much of the essence of programming. In this chapter we are going to look at more complex data. All the procedures functions in chapter operate on simple numerical data, and simple data are not sufficient for many of the problems we wish to address using computation. Programs are typically designed to model complex phenomena, and more often than not one must construct computational objects that have several parts in order to model real-world phenomena that have several aspects. Thus, whereas our focus in chapter was on building abstractions by combining procedures functions to form compound procedures, functions, we turn in this chapter to another key aspect of any programming language: the means it provides for building abstractions by combining data objects to form compound data .",
    "token_count": 291,
    "source_files": [
      "chapter2.xml"
    ]
  },
  {
    "chapter_file": "chapter2_chunks.json",
    "section": null,
    "subsection": "Building Abstractions with Data",
    "chunk_id": "chapter2_chunks_Building_Abstractions_with_Data_2",
    "chunk_index": 2,
    "content": "Why do we want compound data in a programming language? For the same reasons that we want compound procedures: functions: to elevate the conceptual level at which we can design our programs, to increase the modularity of our designs, and to enhance the expressive power of our language. Just as the ability to define procedures declare functions enables us to deal with processes at a higher conceptual level than that of the primitive operations of the language, the ability to construct compound data objects enables us to deal with data at a higher conceptual level than that of the primitive data objects of the language. Consider the task of designing a system to perform add-rat add_rat that takes two rational numbers and produces their sum. In terms of simple data, a rational number can be thought of as two integers: a numerator and a denominator. Thus, we could design a program in which each rational number would be represented by two integers (a numerator and a denominator) and where add-rat add_rat would be implemented by two procedures functions (one producing the numerator of the sum and one producing the denominator). But this would be awkward, because we would then need to explicitly keep track of which numerators corresponded to which denominators. In a system intended to perform many operations on many rational numbers, such bookkeeping details would clutter the programs substantially, to say nothing of what they would do to our minds.",
    "token_count": 275,
    "source_files": [
      "chapter2.xml"
    ]
  },
  {
    "chapter_file": "chapter2_chunks.json",
    "section": null,
    "subsection": "Building Abstractions with Data",
    "chunk_id": "chapter2_chunks_Building_Abstractions_with_Data_3",
    "chunk_index": 3,
    "content": "It would be much better if we could glue together a numerator and denominator to form a pair a compound data object that our programs could manipulate in a way that would be consistent with regarding a rational number as a single conceptual unit. The use of compound data also enables us to increase the modularity of our programs. If we can manipulate rational numbers directly as objects in their own right, then we can separate the part of our program that deals with rational numbers per se from the details of how rational numbers may be represented as pairs of integers. The general technique of isolating the parts of a program that deal with how data objects are represented from the parts of a program that deal with how data objects are used is a powerful design methodology called data abstraction . We will see how data abstraction makes programs much easier to design, maintain, and modify. The use of compound data leads to a real increase in the expressive power of our programming language. Consider the idea of forming a linear combination $ax+by$ . We might like to write a procedure function that would accept $a$ , $b$ , $x$ , and $y$ as arguments and return the value of $ax+by$ .",
    "token_count": 240,
    "source_files": [
      "chapter2.xml"
    ]
  },
  {
    "chapter_file": "chapter2_chunks.json",
    "section": null,
    "subsection": "Building Abstractions with Data",
    "chunk_id": "chapter2_chunks_Building_Abstractions_with_Data_4",
    "chunk_index": 4,
    "content": "This presents no difficulty if the arguments are to be numbers, because we can readily define the procedure declare the function  (define (linear-combination a b x y) (+ (* a x) (* b y))) function linear_combination(a, b, x, y) { return a * x + b * y; }  linear_combination(1, 2, 3, 4); But suppose we are not concerned only with numbers. Suppose we would like to express, in procedural terms, the idea that one can form describe a process that forms linear combinations whenever addition and multiplication are defined for rational numbers, complex numbers, polynomials, or whatever. We could express this as a procedure function of the form (define (linear-combination a b x y) (add (mul a x) (mul b y))) function linear_combination(a, b, x, y) { return add(mul(a, x), mul(b, y)); } where add and mul are not the primitive procedures functions + and * but rather more complex things that will perform the appropriate operations for whatever kinds of data we pass in as the arguments a , b , x , and y . The key point is that the only thing linear-combination linear_combination should need to know about a , b , x , and y is that the procedures functions add and mul will perform the appropriate manipulations.",
    "token_count": 285,
    "source_files": [
      "chapter2.xml"
    ]
  },
  {
    "chapter_file": "chapter2_chunks.json",
    "section": null,
    "subsection": "Building Abstractions with Data",
    "chunk_id": "chapter2_chunks_Building_Abstractions_with_Data_5",
    "chunk_index": 5,
    "content": "From the perspective of the procedure function linear-combination , linear_combination , it is irrelevant what a , b , x , and y are and even more irrelevant how they might happen to be represented in terms of more primitive data. This same example shows why it is important that our programming language provide the ability to manipulate compound objects directly: Without this, there is no way for a procedure function such as linear-combination linear_combination to pass its arguments along to add and mul without having to know their detailed structure. We begin this chapter by implementing the rational-number arithmetic system mentioned above. This will form the background for our discussion of compound data and data abstraction. As with compound procedures, functions, the main issue to be addressed is that of abstraction as a technique for coping with complexity, and we will see how data abstraction enables us to erect suitable abstraction barriers between different parts of a program. We will see that the key to forming compound data is that a programming language should provide some kind of glue so that data objects can be combined to form more complex data objects. There are many possible kinds of glue. Indeed, we will discover how to form compound data using no special data operations at all, only procedures. functions. This will further blur the distinction between procedure function and data, which was already becoming tenuous toward the end of chapter . We will also explore some conventional techniques for representing sequences and trees.",
    "token_count": 283,
    "source_files": [
      "chapter2.xml"
    ]
  },
  {
    "chapter_file": "chapter2_chunks.json",
    "section": null,
    "subsection": "Building Abstractions with Data",
    "chunk_id": "chapter2_chunks_Building_Abstractions_with_Data_6",
    "chunk_index": 6,
    "content": "One key idea in dealing with compound data is the notion of closure that the glue we use for combining data objects should allow us to combine not only primitive data objects, but compound data objects as well. Another key idea is that compound data objects can serve as conventional interfaces for combining program modules in mix-and-match ways. We illustrate some of these ideas by presenting a simple graphics language that exploits closure. We will then augment the representational power of our language by introducing symbolic expressions data whose elementary parts can be arbitrary symbols rather than only numbers. We explore various alternatives for representing sets of objects. We will find that, just as a given numerical function can be computed by many different computational processes, there are many ways in which a given data structure can be represented in terms of simpler objects, and the choice of representation can have significant impact on the time and space requirements of processes that manipulate the data. We will investigate these ideas in the context of symbolic differentiation, the representation of sets, and the encoding of information. Next we will take up the problem of working with data that may be represented differently by different parts of a program. This leads to the need to implement generic operations , which must handle many different types of data. Maintaining modularity in the presence of generic operations requires more powerful abstraction barriers than can be erected with simple data abstraction alone.",
    "token_count": 268,
    "source_files": [
      "chapter2.xml"
    ]
  },
  {
    "chapter_file": "chapter2_chunks.json",
    "section": null,
    "subsection": "Building Abstractions with Data",
    "chunk_id": "chapter2_chunks_Building_Abstractions_with_Data_7",
    "chunk_index": 7,
    "content": "In particular, we introduce data-directed programming as a technique that allows individual data representations to be designed in isolation and then combined additively (i.e., without modification). To illustrate the power of this approach to system design, we close the chapter by applying what we have learned to the implementation of a package for performing symbolic arithmetic on polynomials, in which the coefficients of the polynomials can be integers, rational numbers, complex numbers, and even other polynomials.",
    "token_count": 93,
    "source_files": [
      "chapter2.xml"
    ]
  },
  {
    "chapter_file": "chapter2_chunks.json",
    "section": "Building Abstractions with Data",
    "subsection": "Hierarchical Data and the Closure Property",
    "chunk_id": "chapter2_chunks_Hierarchical_Data_and_the_Closure_Property_1",
    "chunk_index": 1,
    "content": "As we have seen, pairs provide a primitive glue that we can use to construct compound data objects. Figure Figure shows a standard way to visualize a in this case, the pair formed by (cons 1 2) . pair(1, 2) . In this representation, which is called box-and-pointer notation , each object is shown as a pointer to a box. The box for a primitive object contains a representation of the object. For example, the box for a number contains a numeral. The box for a pair is actually a double box, the left part containing (a pointer to) the car of the pair and the right part containing the cdr . In this representation, which is called box-and-pointer notation , each compound object is shown as a pointer to a box. The box for a pair has two parts, the left part containing the head of the pair and the right part containing the tail. We have already seen that cons pair can be used to combine not only numbers but pairs as well. (You made use of this fact, or should have, in doing exercises and .) As a consequence, pairs provide a universal building block from which we can construct all sorts of data structures. Figure Figure shows two ways to use pairs to combine the numbers 1, 2, 3, and 4. Two ways to combine 1, 2, 3, and 4 using pairs.",
    "token_count": 287,
    "source_files": [
      "section2.xml"
    ]
  },
  {
    "chapter_file": "chapter2_chunks.json",
    "section": "Building Abstractions with Data",
    "subsection": "Hierarchical Data and the Closure Property",
    "chunk_id": "chapter2_chunks_Hierarchical_Data_and_the_Closure_Property_2",
    "chunk_index": 2,
    "content": "Two ways to combine 1, 2, 3, and 4 using pairs. The ability to create pairs whose elements are pairs is the essence of list structure s importance as a representational tool. We refer to this ability as the closure property of cons . pair . In general, an operation for combining data objects satisfies the closure property if the results of combining things with that operation can themselves be combined using the same operation. hierarchical structures structures made up of parts, which themselves are made up of parts, and so on. From the outset of chapter , we ve made essential use of closure in dealing with procedures, functions, because all but the very simplest programs rely on the fact that the elements of a combination can themselves be combinations. In this section, we take up the consequences of closure for compound data. We describe some conventional techniques for using pairs to represent sequences and trees, and we exhibit a graphics language that illustrates closure in a vivid way.",
    "token_count": 192,
    "source_files": [
      "section2.xml"
    ]
  },
  {
    "chapter_file": "chapter2_chunks.json",
    "section": "Hierarchical Data and the Closure Property",
    "subsection": "Hierarchical Structures",
    "chunk_id": "chapter2_chunks_Hierarchical_Structures_1",
    "chunk_index": 1,
    "content": "The representation of sequences in terms of lists generalizes naturally to represent sequences whose elements may themselves be sequences. For example, we can regard the object ((1 2) 3 4) [[1, [2, null]], [3, [4, null]]] constructed by (cons (list 1 2) (list 3 4)) pair(list(1, 2), list(3, 4)); as a list of three items, the first of which is itself a list, (1 2) . Indeed, this is suggested by the form in which the result is printed by the interpreter. [1, [2, null]] . Figure Figure shows the representation of this structure in terms of pairs. Structure formed by (cons (list 1 2) (list 3 4)) . Structure formed by pair(list(1, 2), list(3, 4)) .\nAnother way to think of sequences whose elements are sequences is as trees . The elements of the sequence are the branches of the tree, and elements that are themselves sequences are subtrees. Figure Figure shows the structure in figure figure viewed as a tree. The list structure in figure viewed as a tree. The list structure in figure viewed as a tree.",
    "token_count": 259,
    "source_files": [
      "subsection2.xml"
    ]
  },
  {
    "chapter_file": "chapter2_chunks.json",
    "section": "Hierarchical Data and the Closure Property",
    "subsection": "Hierarchical Structures",
    "chunk_id": "chapter2_chunks_Hierarchical_Structures_2",
    "chunk_index": 2,
    "content": "Recursion length length procedure function of section with the count-leaves count_leaves procedure, function, which returns the total number of leaves of a tree: tree_x (define x (cons (list 1 2) (list 3 4))) const x = pair(list(1, 2), list(3, 4)); length_tree_x tree_x 3 (length x) 3 length(x); 3 count_leaves_tree_x tree_x count_leaves 4 (count-leaves x) 4 count_leaves(x); 4 list_x_x tree_x 3 (list x x) (((1 2) 3 4) ((1 2) 3 4)) list(x, x); length(head(tail(list(x, x)))); list(list(list(1, 2), 3, 4), list(list(1, 2), 3, 4)) length_list_x_x tree_x 2 (length (list x x)) 2 length(list(x, x)); 2 count_leaves_list_x_x tree_x count_leaves 8 (count-leaves (list x x)) 8 count_leaves(list(x, x)); 8\nTo implement count-leaves , count_leaves , recall the recursive plan for computing length : length : Length The length of a list x is 1 plus length the length of the cdr tail of x . Length The length of the empty list is 0. Count-leaves The function count_leaves is similar. The value for the empty list is the same: Count-leaves count_leaves of the empty list is 0. But in the reduction step, where we strip off the car head of the list, we must take into account that the car head may itself be a tree whose leaves we need to count. Thus, the appropriate reduction step is Count-leaves count_leaves of a tree x is count-leaves count_leaves of the car head of x plus count-leaves count_leaves of the cdr tail of x . Finally, by taking car s head s we reach actual leaves, so we need another base case: Count-leaves count_leaves of a leaf is 1. To aid in writing recursive procedures functions on trees, Scheme our JavaScript environment provides the primitive predicate pair? , is_pair , which tests whether its argument is a pair. Here is the complete procedure: function: count_leaves  4 (define (count-leaves x) (cond ((null? x) 0) ((not (pair? x)) 1) (else (+ (count-leaves (car x)) (count-leaves (cdr x)))))) function count_leaves(x) { return is_null(x) ? 0 : ! is_pair(x) ? 1 : count_leaves(head(x)) + count_leaves(tail(x)); }  (count-leaves (cons (list 1 2) (list 3 4))) count_leaves(pair(list(1, 2), list(3, 4)));",
    "token_count": 627,
    "source_files": [
      "subsection2.xml"
    ]
  },
  {
    "chapter_file": "chapter2_chunks.json",
    "section": "Hierarchical Data and the Closure Property",
    "subsection": "Hierarchical Structures",
    "chunk_id": "chapter2_chunks_Hierarchical_Structures_3",
    "chunk_index": 3,
    "content": "Just as map is a powerful abstraction for dealing with sequences, map together with recursion is a powerful abstraction for dealing with trees. For instance, the scale-tree scale_tree procedure, function, analogous to scale-list scale_list of section , takes as arguments a numeric factor and a tree whose leaves are numbers. It returns a tree of the same shape, where each number is multiplied by the factor. The recursive plan for scale-tree scale_tree is similar to the one for count-leaves : count_leaves : scale_tree  10 (define (scale-tree tree factor) (cond ((null? tree) nil) ((not (pair? tree)) (* tree factor)) (else (cons (scale-tree (car tree) factor) (scale-tree (cdr tree) factor))))) function scale_tree(tree, factor) { return is_null(tree) ? null : ! is_pair(tree) ? tree * factor : pair(scale_tree(head(tree), factor), scale_tree(tail(tree), factor)); }  scale_tree (scale-tree (list 1 (list 2 (list 3 4) 5) (list 6 7)) 10) (10 (20 (30 40) 50) (60 70)) scale_tree(list(1, list(2, list(3, 4), 5), list(6, 7)), 10); head(scale_tree(list(1, list(2, list(3, 4), 5), list(6, 7)), 10)); list(10, list(20, list(30, 40), 50), list(60, 70))",
    "token_count": 336,
    "source_files": [
      "subsection2.xml"
    ]
  },
  {
    "chapter_file": "chapter2_chunks.json",
    "section": "Hierarchical Data and the Closure Property",
    "subsection": "Hierarchical Structures",
    "chunk_id": "chapter2_chunks_Hierarchical_Structures_4",
    "chunk_index": 4,
    "content": "Another way to implement scale-tree scale_tree is to regard the tree as a sequence of sub-trees and use map . map . We map over the sequence, scaling each sub-tree in turn, and return the list of results. In the base case, where the tree is a leaf, we simply multiply by the factor:  (scale-tree (list 1 (list 2 (list 3 4) 5) (list 6 7)) 10) scale_tree(list(1, list(2, list(3, 4), 5), list(6, 7)), 10); head(scale_tree(list(1, list(2, list(3, 4), 5), list(6, 7)), 10)); scale_tree_with_map  10 (define (scale-tree tree factor) (map (lambda (sub-tree) (if (pair? sub-tree) (scale-tree sub-tree factor) (* sub-tree factor))) tree)) function scale_tree(tree, factor) { return map(sub_tree => is_pair(sub_tree) ? scale_tree(sub_tree, factor) : sub_tree * factor, tree); } Many tree operations can be implemented by similar combinations of sequence operations and recursion.",
    "token_count": 253,
    "source_files": [
      "subsection2.xml"
    ]
  },
  {
    "chapter_file": "chapter3_chunks.json",
    "section": null,
    "subsection": "Modularity, Objects, and State",
    "chunk_id": "chapter3_chunks_Modularity,_Objects,_and_State_1",
    "chunk_index": 1,
    "content": "The preceding chapters introduced the basic elements from which programs are made. We saw how primitive procedures functions and primitive data are combined to construct compound entities, and we learned that abstraction is vital in helping us to cope with the complexity of large systems. But these tools are not sufficient for designing programs. Effective program synthesis also requires organizational principles that can guide us in formulating the overall design of a program. In particular, we need strategies to help us structure large systems so that they will be modular , that is, so that they can be divided naturally into coherent parts that can be separately developed and maintained. One powerful design strategy, which is particularly appropriate to the construction of programs for\nTo a large extent, then, the way we organize a large program is dictated by our perception of the system to be modeled. In this chapter we will investigate two prominent organizational strategies arising from two rather different world views of the structure of systems. The first organizational strategy concentrates on objects , viewing a large system as a collection of distinct objects whose behaviors may change over time. An alternative organizational strategy concentrates on the streams of information that flow in the system, much as an electrical engineer views a signal-processing system. Both the object-based approach and the stream-processing approach raise significant linguistic issues in programming. With objects, we must be concerned with how a computational object can change and yet maintain its identity.",
    "token_count": 273,
    "source_files": [
      "chapter3.xml"
    ]
  },
  {
    "chapter_file": "chapter3_chunks.json",
    "section": null,
    "subsection": "Modularity, Objects, and State",
    "chunk_id": "chapter3_chunks_Modularity,_Objects,_and_State_2",
    "chunk_index": 2,
    "content": "This will force us to abandon our old substitution model of computation (section ) in favor of a more mechanistic but less theoretically tractable environment model of computation. The difficulties of dealing with objects, change, and identity are a fundamental consequence of the need to grapple with time in our computational models. These difficulties become even greater when we allow the possibility of concurrent execution of programs. The stream approach can be most fully exploited when we decouple simulated time in our model from the order of the events that take place in the computer during evaluation. We will accomplish this using a technique known as delayed evaluation .",
    "token_count": 120,
    "source_files": [
      "chapter3.xml"
    ]
  },
  {
    "chapter_file": "chapter3_chunks.json",
    "section": "Modeling with Mutable Data",
    "subsection": "Representing Tables",
    "chunk_id": "chapter3_chunks_Representing_Tables_1",
    "chunk_index": 1,
    "content": "When we studied various ways of representing sets in chapter , we mentioned in section the task of maintaining a table of records , we made extensive use of two-dimensional tables, in which information is stored and retrieved using two keys. Here we see how to build tables as mutable list structures. We first consider a car s head s point to successive records. These gluing pairs are called the backbone of the table. In order to have a place that we can change when we add a new record to the table, we build the table as a headed list . A headed list has a special backbone pair at the beginning, which holds a dummy record in this case the arbitrarily chosen symbol *table* . string \"*table*\" . Figure Figure shows the box-and-pointer diagram for the table a: 1 b: 2 c: 3 a: 1 b: 2 c: 3 A table represented as a headed list. A table represented as a headed list. To extract information from a table we use the lookup procedure, function, which takes a key as argument and returns the associated value (or false undefined if there is no value stored under that key). Lookup The function lookup is defined in terms of the assoc operation, which expects a key and a list of records as arguments. Note that assoc never sees the dummy record. Assoc The function assoc returns the record that has the given key as its car head .",
    "token_count": 284,
    "source_files": [
      "subsection3.xml"
    ]
  },
  {
    "chapter_file": "chapter3_chunks.json",
    "section": "Modeling with Mutable Data",
    "subsection": "Representing Tables",
    "chunk_id": "chapter3_chunks_Representing_Tables_2",
    "chunk_index": 2,
    "content": "Lookup The function lookup then checks to see that the resulting record returned by assoc is not false, undefined , and returns the value (the cdr ) tail ) of the record. make_table1 insert_into_table1 const t = make_table(); insert(\"a\", 10, t); lookup(\"a\", t); lookup1  10 (define (lookup key table) (let ((record (assoc key (cdr table)))) (if record (cdr record) false))) (define (assoc key records) (cond ((null? records) false) ((equal? key (caar records)) (car records)) (else (assoc key (cdr records))))) function lookup(key, table) { const record = assoc(key, tail(table)); return is_undefined(record) ? undefined : tail(record); } function assoc(key, records) { return is_null(records) ? undefined : equal(key, head(head(records))) ? head(records) : assoc(key, tail(records)); }\nTo insert a value in a table under a specified key, we first use assoc to see if there is already a record in the table with this key. If not, we form a new record by cons ing pair ing the key with the value, and insert this at the head of the table s list of records, after the dummy record. If there already is a record with this key, we set the cdr tail of this record to the designated new value.",
    "token_count": 290,
    "source_files": [
      "subsection3.xml"
    ]
  },
  {
    "chapter_file": "chapter3_chunks.json",
    "section": "Modeling with Mutable Data",
    "subsection": "Representing Tables",
    "chunk_id": "chapter3_chunks_Representing_Tables_3",
    "chunk_index": 3,
    "content": "The header of the table provides us with a fixed location to modify in order to insert the new record. lookup1 insert_into_table1 (define (insert! key value table) (let ((record (assoc key (cdr table)))) (if record (set-cdr! record value) (set-cdr! table (cons (cons key value) (cdr table))))) 'ok) function insert(key, value, table) { const record = assoc(key, tail(table)); if (is_undefined(record)) { set_tail(table, pair(pair(key, value), tail(table))); } else { set_tail(record, value); } return \"ok\"; }",
    "token_count": 133,
    "source_files": [
      "subsection3.xml"
    ]
  },
  {
    "chapter_file": "chapter3_chunks.json",
    "section": "Modeling with Mutable Data",
    "subsection": "Representing Tables",
    "chunk_id": "chapter3_chunks_Representing_Tables_4",
    "chunk_index": 4,
    "content": "To construct a new table, we simply create a list containing the symbol *table* : just the string \"*table*\" : make_table1 (define (make-table) (list '*table*)) function make_table() { return list(\"*table*\"); }\nIn a two-dimensional table, each value is indexed by two keys. We can construct such a table as a one-dimensional table in which each key identifies a subtable. Figure Figure shows the box-and-pointer diagram for the table math: +: 43 -: 45 *: 42 letters: a: 97 b: 98 \"math\": \"+\": 43 \"-\": 45 \"*\": 42 \"letters\": \"a\": 97 \"b\": 98 which has two subtables. (The subtables don t need a special header symbol, string, since the key that identifies the subtable serves this purpose.) A two-dimensional table. A two-dimensional table.",
    "token_count": 189,
    "source_files": [
      "subsection3.xml"
    ]
  },
  {
    "chapter_file": "chapter3_chunks.json",
    "section": "Modeling with Mutable Data",
    "subsection": "Representing Tables",
    "chunk_id": "chapter3_chunks_Representing_Tables_5",
    "chunk_index": 5,
    "content": "When we look up an item, we use the first key to identify the correct subtable. Then we use the second key to identify the record within the subtable.  make_table2 insert_into_table2 const t = list(\"*table*\"); insert(\"a\", \"b\", 10, t); lookup(\"a\", \"b\", t); just_assoc function assoc(key, records) { return is_null(records) ? undefined : equal(key, head(head(records))) ? head(records) : assoc(key, tail(records)); } lookup2 just_assoc  10 (define (lookup key-1 key-2 table) (let ((subtable (assoc key-1 (cdr table)))) (if subtable (let ((record (assoc key-2 (cdr subtable)))) (if record (cdr record) false)) false))) function lookup(key_1, key_2, table) { const subtable = assoc(key_1, tail(table)); if (is_undefined(subtable)) { return undefined; } else { const record = assoc(key_2, tail(subtable)); return is_undefined(record) ? undefined : tail(record); } }\nTo insert a new item under a pair of keys, we use assoc to see if there is a subtable stored under the first key. If not, we build a new subtable containing the single record ( key-2 , ( key_2 , value ) and insert it into the table under the first key. If a subtable already exists for the first key, we insert the new record into this subtable, using the insertion method for one-dimensional tables described above: just_assoc insert_into_table2 (define (insert! key-1 key-2 value table) (let ((subtable (assoc key-1 (cdr table)))) (if subtable (let ((record (assoc key-2 (cdr subtable)))) (if record (set-cdr! record value) (set-cdr! subtable (cons (cons key-2 value) (cdr subtable))))) (set-cdr! table (cons (list key-1 (cons key-2 value)) (cdr table))))) 'ok) function insert(key_1, key_2, value, table) { const subtable = assoc(key_1, tail(table)); if (is_undefined(subtable)) { set_tail(table, pair(list(key_1, pair(key_2, value)), tail(table))); } else { const record = assoc(key_2, tail(subtable)); if (is_undefined(record)) { set_tail(subtable, pair(pair(key_2, value), tail(subtable))); } else { set_tail(record, value); } } return \"ok\"; }",
    "token_count": 556,
    "source_files": [
      "subsection3.xml"
    ]
  },
  {
    "chapter_file": "chapter3_chunks.json",
    "section": "Modeling with Mutable Data",
    "subsection": "Representing Tables",
    "chunk_id": "chapter3_chunks_Representing_Tables_6",
    "chunk_index": 6,
    "content": "The lookup and insert! insert operations defined above take the table as an argument. This enables us to use programs that access more than one table. Another way to deal with multiple tables is to have separate lookup and insert! insert procedures functions for each table. We can do this by representing a table procedurally, as an object that maintains an internal table as part of its local state. When sent an appropriate message, this table object supplies the procedure function with which to operate on the internal table. Here is a generator for two-dimensional tables represented in this fashion: make_table2 just_assoc (define (make-table) (let ((local-table (list '*table*))) (define (lookup key-1 key-2) (let ((subtable (assoc key-1 (cdr local-table)))) (if subtable (let ((record (assoc key-2 (cdr subtable)))) (if record (cdr record) false)) false))) (define (insert! key-1 key-2 value) (let ((subtable (assoc key-1 (cdr local-table)))) (if subtable (let ((record (assoc key-2 (cdr subtable)))) (if record (set-cdr! record value) (set-cdr! subtable (cons (cons key-2 value) (cdr subtable))))) (set-cdr! local-table (cons (list key-1 (cons key-2 value)) (cdr local-table))))) 'ok) (define (dispatch m) (cond ((eq? m 'lookup-proc) lookup) ((eq? m 'insert-proc!) insert!) (else (error \"Unknown operation - - TABLE\" m)))) dispatch)) function make_table() { const local_table = list(\"*table*\"); function lookup(key_1, key_2) { const subtable = assoc(key_1, tail(local_table)); if (is_undefined(subtable)) { return undefined; } else { const record = assoc(key_2, tail(subtable)); return is_undefined(record) ? undefined : tail(record); } } function insert(key_1, key_2, value) { const subtable = assoc(key_1, tail(local_table)); if (is_undefined(subtable)) { set_tail(local_table, pair(list(key_1, pair(key_2, value)), tail(local_table))); } else { const record = assoc(key_2, tail(subtable)); if (is_undefined(record)) { set_tail(subtable, pair(pair(key_2, value), tail(subtable))); } else { set_tail(record, value); } } } function dispatch(m) { return m === \"lookup\" ? lookup : m === \"insert\" ? insert : error(m, \"unknown operation -- table\"); } return dispatch; }",
    "token_count": 567,
    "source_files": [
      "subsection3.xml"
    ]
  },
  {
    "chapter_file": "chapter3_chunks.json",
    "section": "Modeling with Mutable Data",
    "subsection": "Representing Tables",
    "chunk_id": "chapter3_chunks_Representing_Tables_7",
    "chunk_index": 7,
    "content": "Using make-table , make_table , we could get and put operations used in section for data-directed programming, as follows:  put(\"a\", \"b\", 10); get(\"a\", \"b\"); operation_table make_table2  10 const operation_table = make_table(); const get = operation_table(\"lookup\"); const put = operation_table(\"insert\"); Get The function get takes as arguments two keys, and put takes as arguments two keys and a value. Both operations access the same local table, which is encapsulated within the object created by the call to make-table . make_table .",
    "token_count": 120,
    "source_files": [
      "subsection3.xml"
    ]
  },
  {
    "chapter_file": "chapter3_chunks.json",
    "section": "Modularity, Objects, and State",
    "subsection": "Modeling with Mutable Data",
    "chunk_id": "chapter3_chunks_Modeling_with_Mutable_Data_1",
    "chunk_index": 1,
    "content": "Chapter dealt with compound data as a means for constructing computational objects that have several parts, in order to model real-world objects that have several aspects. In that chapter we introduced the discipline of data abstraction, according to which data structures are specified in terms of constructors, which create data objects, and selectors, which access the parts of compound data objects. But we now know that there is another aspect of data that chapter did not address. The desire to model systems composed of objects that have changing state leads us to the need to modify compound data objects, as well as to construct and select from them. In order to model compound objects with changing state, we will design data abstractions to include, in addition to selectors and constructors, operations called mutators , which modify data objects. For instance, modeling a banking system requires us to change account balances. Thus, a data structure for representing bank accounts might admit an operation (set-balance! $account$ $new$-$value$) set_balance( account , new-value ) that changes the balance of the designated account to the designated new value. Data objects for which mutators are defined are known as mutable data objects . Chapter introduced pairs as a general-purpose glue for synthesizing compound data. We begin this section by defining basic mutators for pairs, so that pairs can serve as building blocks for constructing mutable data objects.",
    "token_count": 274,
    "source_files": [
      "section3.xml"
    ]
  },
  {
    "chapter_file": "chapter3_chunks.json",
    "section": "Modularity, Objects, and State",
    "subsection": "Modeling with Mutable Data",
    "chunk_id": "chapter3_chunks_Modeling_with_Mutable_Data_2",
    "chunk_index": 2,
    "content": "These mutators greatly enhance the representational power of pairs, enabling us to build data structures other than the sequences and trees that we worked with in section . We also present some examples of simulations in which complex systems are modeled as collections of objects with local state.",
    "token_count": 52,
    "source_files": [
      "section3.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": null,
    "subsection": "Metalinguistic Abstraction",
    "chunk_id": "chapter4_chunks_Metalinguistic_Abstraction_1",
    "chunk_index": 1,
    "content": "In our study of program design, we have seen that expert programmers control the complexity of their designs with the same general techniques used by designers of all complex systems. They combine primitive elements to form compound objects, they abstract compound objects to form higher-level building blocks, and they preserve modularity by adopting appropriate large-scale views of system structure. In illustrating these techniques, we have used Lisp JavaScript as a language for describing processes and for constructing computational data objects and processes to model complex phenomena in the real world. However, as we confront increasingly complex problems, we will find that Lisp, JavaScript, or indeed any fixed programming language, is not sufficient for our needs. We must constantly turn to new languages in order to express our ideas more effectively. Establishing new languages is a powerful strategy for controlling complexity in engineering design; we can often enhance our ability to deal with a complex problem by adopting a new language that enables us to describe (and hence to think about) the problem in a different way, using primitives, means of combination, and means of abstraction that are particularly well suited to the problem at hand. Programming is endowed with a multitude of languages. There are physical languages, such as the procedure definition, function declaration, that are appropriate to the larger-scale organization of systems. Metalinguistic abstraction establishing plays an important role in all branches of engineering design.",
    "token_count": 271,
    "source_files": [
      "chapter4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": null,
    "subsection": "Metalinguistic Abstraction",
    "chunk_id": "chapter4_chunks_Metalinguistic_Abstraction_2",
    "chunk_index": 2,
    "content": "It is particularly important to computer programming, because in programming not only can we formulate new languages but we can also implement these languages by constructing evaluators. An evaluator (or interpreter ) for a programming language is a procedure function that, when applied to a statement or expression an expression of the language, performs the actions required to evaluate that statement or expression. It is no exaggeration to regard this as the most fundamental idea in programming: The evaluator, which determines the meaning of statements and expressions in a programming language, is just another program. To appreciate this point is to change our images of ourselves as programmers. We come to see ourselves as designers of languages, rather than only users of languages designed by others. In fact, we can regard almost any program as the evaluator for some language. For instance, the polynomial manipulation system of section embodies the rules of polynomial arithmetic and implements them in terms of operations on list-structured data. If we augment this system with procedures functions to read and print polynomial expressions, we have the core of a special-purpose language for dealing with problems in symbolic mathematics. The digital-logic simulator of section and the constraint propagator of section are legitimate languages in their own right, each with its own primitives, means of combination, and means of abstraction. Seen from this perspective, the technology for coping with large-scale computer systems merges with the technology for building new computer languages, and\nWe now embark on a tour of the technology by which languages are established in terms of other languages.",
    "token_count": 300,
    "source_files": [
      "chapter4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": null,
    "subsection": "Metalinguistic Abstraction",
    "chunk_id": "chapter4_chunks_Metalinguistic_Abstraction_3",
    "chunk_index": 3,
    "content": "In this chapter we shall use Lisp JavaScript as a base, implementing evaluators as Lisp JavaScript procedures. functions. We will take the first step in understanding how languages are implemented by building an evaluator for Lisp JavaScript itself. The language implemented by our evaluator will be a subset of the Scheme dialect of Lisp that we use in this book. JavaScript. Although the evaluator described in this chapter is written for a particular dialect of Lisp, subset of JavaScript, it contains the essential structure of an evaluator for any expression-oriented language designed for writing programs for a sequential machine. (In fact, most language processors contain, deep within them, a little Lisp evaluator.) The evaluator has been simplified for the purposes of illustration and discussion, and some features have been left out that would be important to include in a production-quality Lisp JavaScript system. Nevertheless, this simple evaluator is adequate to execute most of the programs in this book. An important advantage of making the evaluator accessible as a Lisp JavaScript program is that we can implement alternative evaluation rules by describing these as modifications to the evaluator program. One place where we can use this power to good effect is to gain extra control over the ways in which computational models embody the notion of time, which was so central to the discussion in chapter . There, we mitigated some of the complexities of state and assignment by using streams to decouple the representation of time in the world from time in the computer.",
    "token_count": 281,
    "source_files": [
      "chapter4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": null,
    "subsection": "Metalinguistic Abstraction",
    "chunk_id": "chapter4_chunks_Metalinguistic_Abstraction_4",
    "chunk_index": 4,
    "content": "Our stream programs, however, were sometimes cumbersome, because they were constrained by the applicative-order evaluation of Scheme. JavaScript. In section , we ll change the underlying language to provide for a more elegant approach, by modifying the evaluator to provide for normal-order evaluation . Section implements a more ambitious linguistic change, whereby statements and expressions have many values, rather than just a single value. In this language of nondeterministic computing , it is natural to express processes that generate all possible values for statements and expressions and then search for those values that satisfy certain constraints. In terms of models of computation and time, this is like having time branch into a set of possible futures and then searching for appropriate time lines. With our nondeterministic evaluator, keeping track of multiple values and performing searches are handled automatically by the underlying mechanism of the language. In section we implement a logic-programming language in which knowledge is expressed in terms of relations, rather than in terms of computations with inputs and outputs. Even though this makes the language drastically different from Lisp, JavaScript, or indeed from any conventional language, we will see that the logic-programming evaluator shares the essential structure of the Lisp JavaScript evaluator.",
    "token_count": 235,
    "source_files": [
      "chapter4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_1",
    "chunk_index": 1,
    "content": "Section described how the query system works. Now we fill in the details by presenting a complete implementation of the system.",
    "token_count": 23,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_2",
    "chunk_index": 2,
    "content": "The the evaluator qeval evaluate_query together with an initial frame stream consisting of a single empty frame. The result of the evaluation is a stream of frames generated by satisfying the query with variable values found in the data base. These frames are used to form a new stream consisting of copies of the original query in which the variables are instantiated with values supplied by the stream of frames, and this final stream is printed at the terminal: displayed: lp_header // functions from SICP JS 4.4.4 query_driver_loop functions_4_1_1 functions_4_1_2 functions_4_1_3 functions_4_1_4 lp_header is_assertion instantiate evaluate_query singleton_stream add_rule_or_assertion put_and disjoin negate javascript_predicate display_stream always_true is_variable_2 is_variable_4 convert_to_query_syntax unparse user_read  (define input-prompt \";;; Query input:\") (define output-prompt \";;; Query results:\") (define (query-driver-loop) (prompt-for-input input-prompt) (let ((q (query-syntax-process (read)))) (cond ((assertion-to-be-added? q) (add-rule-or-assertion! (add-assertion-body q)) (newline) (display \"Assertion added to data base.\") (query-driver-loop)) (else (newline) (display output-prompt) (display-stream (stream-map (lambda (frame) (instantiate q frame (lambda (v f) (contract-question-mark v)))) (qeval q (singleton-stream '())))) (query-driver-loop))))) const input_prompt = \"Query input:\"; const output_prompt = \"Query results:\"; function query_driver_loop() { const input = user_read(input_prompt) + \";\"; if (is_null(input)) { display(\"evaluator terminated\"); } else { const expression = parse(input); const query = convert_to_query_syntax(expression); if (is_assertion(query)) { add_rule_or_assertion(assertion_body(query)); display(\"Assertion added to data base.\"); } else { display(output_prompt); display_stream( stream_map( frame => unparse(instantiate_expression(expression, frame)), evaluate_query(query, singleton_stream(null)))); } return query_driver_loop(); } } const input_prompt = \"Query input:\"; function query_driver_loop() { const input = user_read(input_prompt); if (is_null(input)) { display(\"--- evaluator terminated ---\"); } else { const exp = parse(input + \";\"); const q = convert_to_query_syntax(exp); display(\"---- driver loop input -----\"); display(unparse(exp)); if (is_assertion(q)) { add_rule_or_assertion(assertion_body(q)); display(\"Assertion added to data base.\"); } else { display(\"------ query results -------\", \"\"); display_stream( stream_map( frame => unparse(instantiate_expression(exp, frame)), evaluate_query(q, singleton_stream(null)))); } return query_driver_loop(); } }  append_to_form query_driver_loop(); // enter: append_to_form($x, $y, list(\"a\", \"b\", \"c\", \"d\"))  parse_query_verbose('assert(son(\"Adam\", \"Cain\"))'); parse_query_verbose('son(\"Adam\", x)'); process_query query_driver_loop  function process_query(input) { if (is_null(input)) { display(\"--- evaluator terminated ---\"); } else { const exp = parse(input + \";\"); const q = convert_to_query_syntax(exp); display(\"---- driver loop input -----\"); display(unparse(exp)); if (is_assertion(q)) { add_rule_or_assertion(assertion_body(q)); display(\"Assertion added to data base.\"); } else { display(\"------ query results -------\", \"\"); display_stream( stream_map( frame => unparse(instantiate_expression(exp, frame)), evaluate_query(q, singleton_stream(null)))); } } } function first_answer(input) { const exp = parse(input + \";\"); const q = convert_to_query_syntax(exp); const frames = evaluate_query(q, singleton_stream(null)); return is_null(frames) ? \"no matching data\" : unparse(instantiate_expression(exp, head(frames))); } function process_query(input) { if (is_null(input)) { display(\"--- evaluator terminated ---\"); } else { const exp = parse(input + \";\"); const q = convert_to_query_syntax(exp); if (is_assertion(q)) { add_rule_or_assertion(assertion_body(q)); } else { display(\"------ query results -------\", \"\"); display_stream( stream_map( frame => unparse(instantiate_expression(exp, frame)), evaluate_query(q, singleton_stream(null)))); } } } function first_answer(input) { const exp = parse(input + \";\"); const q = convert_to_query_syntax(exp); const frames = evaluate_query(q, singleton_stream(null)); return is_null(frames) ? \"no matching data\" : unparse(instantiate_expression(exp, head(frames))); } Here, as in the other evaluators in this chapter, we use an assertion-to-be-added? and the selector add-assertion-body , is given in section . Add-rule-or-assertion! is defined in section . Here, as in the other evaluators in this chapter, we use parse to transform a component of the query language given as a string into a JavaScript syntax representation. (We append a semicolon to the input expression string because parse expects a statement.) Then we further transform the syntax representation to a conceptual level appropriate for the query system using convert_to_query_syntax , which is declared in section along with the predicate is_assertion and the selector assertion_body . The function add_rule_or_assertion is declared in section . The frames resulting from query evaluation are used to instantiate the syntax representation, and the result is unparsed into a string for display. The functions instantiate_expression and unparse are declared in section .",
    "token_count": 1175,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_3",
    "chunk_index": 3,
    "content": "Before doing any processing on an input expression, the driver loop transforms it syntactically into a form that makes the processing more efficient. This involves changing the query-syntax-process and contract-question-mark (section ). To ?x in exp is bound to ?y as the result of unification and ?y is in turn bound to 5). The action to take if a variable cannot be instantiated is given by a procedural argument to instantiate . instantiate make_binding variable express  (define (instantiate exp frame unbound-var-handler) (define (copy exp) (cond ((var? exp) (let ((binding (binding-in-frame exp frame))) (if binding (copy (binding-value binding)) (unbound-var-handler exp frame)))) ((pair? exp) (cons (copy (car exp)) (copy (cdr exp)))) (else exp))) (copy exp)) The procedures that manipulate bindings are defined in section . The qeval evaluate_query procedure, function, called by the query-driver-loop , query_driver_loop , is the basic evaluator of the query system. It takes as inputs a query and a stream of frames, and it returns a stream of extended frames. It identifies special syntactic forms by a get and put , just as we did in implementing generic operations in chapter . Any query that is not identified as a special syntactic form is assumed to be a simple query, to be processed by simple-query . simple_query .",
    "token_count": 287,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_4",
    "chunk_index": 4,
    "content": "evaluate_query operation_table_from_chapter_3 operation_table simple_query type  (define (qeval query frame-stream) (let ((qproc (get (type query) 'qeval))) (if qproc (qproc (contents query) frame-stream) (simple-query query frame-stream)))) function evaluate_query(query, frame_stream) { const qfun = get(type(query), \"evaluate_query\"); return is_undefined(qfun) ? simple_query(query, frame_stream) : qfun(contents(query), frame_stream); } Type The functions type and contents , defined in section , implement the abstract syntax of the special forms. the abstract syntax of the syntactic forms. The simple-query simple_query procedure function handles simple queries. It takes as arguments a simple query (a pattern) together with a stream of frames, and it returns the stream formed by extending each frame by all data-base matches of the query.",
    "token_count": 183,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_5",
    "chunk_index": 5,
    "content": "simple_query stream_flatmap find_assertions apply_rules  (define (simple-query query-pattern frame-stream) (stream-flatmap (lambda (frame) (stream-append-delayed (find-assertions query-pattern frame) (delay (apply-rules query-pattern frame)))) frame-stream)) function simple_query(query_pattern, frame_stream) { return stream_flatmap( frame => stream_append_delayed( find_assertions(query_pattern, frame), () => apply_rules(query_pattern, frame)), frame_stream); }\nFor each frame in the input stream, we use find-assertions find_assertions (section ) to match the pattern against all assertions in the data base, producing a stream of extended frames, and we use apply-rules apply_rules (section ) to apply all possible rules, producing another stream of extended frames. These two streams are combined (using stream-append-delayed , stream_append_delayed , section ) to make a stream of all the ways that the given pattern can be satisfied consistent with the original frame (see exercise ). The streams for the individual input frames are combined using stream-flatmap stream_flatmap (section ) to form one large stream of all the ways that any of the frames in the original input stream can be extended to produce a match with the given pattern. And by the We handle and queries as illustrated in figure with the conjoin procedure. Conjoin function, which takes as inputs the conjuncts and the frame stream and returns the stream of extended frames.",
    "token_count": 297,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_6",
    "chunk_index": 6,
    "content": "First, conjoin processes the stream of frames to find the stream of all possible frame extensions that satisfy the first query in the conjunction. Then, using this as the new frame stream, it recursively applies conjoin to the rest of the queries. conjoin is_empty_conjunction operation_table_from_chapter_3 operation_table is_empty_conjunction stream_append_delayed  (define (conjoin conjuncts frame-stream) (if (empty-conjunction? conjuncts) frame-stream (conjoin (rest-conjuncts conjuncts) (qeval (first-conjunct conjuncts) frame-stream)))) function conjoin(conjuncts, frame_stream) { return is_empty_conjunction(conjuncts) ? frame_stream : conjoin(rest_conjuncts(conjuncts), evaluate_query(first_conjunct(conjuncts), frame_stream)); } The expression statement put_and conjoin  (put 'and 'qeval conjoin) put(\"and\", \"evaluate_query\", conjoin); sets up qeval evaluate_query to dispatch to conjoin when an and form is encountered. Or We handle or queries similarly, as shown in figure . figure . The output streams for the various disjuncts of the or are computed separately and merged using the interleave-delayed interleave_delayed procedure function from section . (See exercises and .)",
    "token_count": 278,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_7",
    "chunk_index": 7,
    "content": "disjoin operation_table_from_chapter_3 operation_table is_empty_conjunction stream_append_delayed  (define (disjoin disjuncts frame-stream) (if (empty-disjunction? disjuncts) the-empty-stream (interleave-delayed (qeval (first-disjunct disjuncts) frame-stream) (delay (disjoin (rest-disjuncts disjuncts) frame-stream))))) (put 'or 'qeval disjoin) function disjoin(disjuncts, frame_stream) { return is_empty_disjunction(disjuncts) ? null : interleave_delayed( evaluate_query(first_disjunct(disjuncts), frame_stream), () => disjoin(rest_disjuncts(disjuncts), frame_stream)); } put(\"or\", \"evaluate_query\", disjoin);\nThe predicates and selectors for the syntax representation of conjuncts and disjuncts are given in section . Not The not syntactic form is handled by the method outlined in section . We attempt to extend each frame in the input stream to satisfy the query being negated, and we include a given frame in the output stream only if it cannot be extended. negate operation_table_from_chapter_3 operation_table stream_flatmap singleton_stream  (define (negate operands frame-stream) (stream-flatmap (lambda (frame) (if (stream-null?",
    "token_count": 283,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_8",
    "chunk_index": 8,
    "content": "(qeval (negated-query operands) (singleton-stream frame))) (singleton-stream frame) the-empty-stream)) frame-stream)) (put 'not 'qeval negate) function negate(exps, frame_stream) { return stream_flatmap( frame => is_null(evaluate_query(negated_query(exps), singleton_stream(frame))) ? singleton_stream(frame) : null, frame_stream); } put(\"not\", \"evaluate_query\", negate);\nLisp-value The javascript_predicate syntactic form is a filter similar to not . Each frame in the stream is used to instantiate the variables in the pattern, the indicated predicate is applied, and the frames for which the predicate returns false are filtered out of the input stream. An error results if there are unbound pattern variables. Each frame in the stream is used to instantiate the variables in the predicate, the instantiated predicate is evaluated, and the frames for which the predicate evaluates to false are filtered out of the input stream. The instantiated predicate is evaluated using evaluate from section with the_global_environment and thus can handle any JavaScript expression, as long as all pattern variables are instantiated prior to evaluation.",
    "token_count": 225,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_9",
    "chunk_index": 9,
    "content": "compound_queries_4 process_query first_answer('and(salary(person, amount), javascript_predicate(amount > 50000))'); // parse_query_verbose('and(salary(person, amount), javascript_predicate(amount > 50000))', \"verbose\"); javascript_predicate operation_table_from_chapter_3 operation_table stream_flatmap singleton_stream  (define (lisp-value call frame-stream) (stream-flatmap (lambda (frame) (if (execute (instantiate call frame (lambda (v f) (error \"Unknown pat var - - LISP-VALUE\" v)))) (singleton-stream frame) the-empty-stream)) frame-stream)) (put 'lisp-value 'qeval lisp-value) function javascript_predicate(exps, frame_stream) { return stream_flatmap( frame => evaluate(instantiate_expression( javascript_predicate_expression(exps), frame), the_global_environment) ? singleton_stream(frame) : null, frame_stream); } put(\"javascript_predicate\", \"evaluate_query\", javascript_predicate);\nExecute , which applies the predicate to the arguments, must eval the predicate expression to get the procedure to apply. However, it must not evaluate the arguments, since they are already the actual arguments, not expressions whose evaluation (in Lisp) will produce the arguments. Note that execute is implemented using eval and apply from the underlying Lisp system.",
    "token_count": 265,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_10",
    "chunk_index": 10,
    "content": "execute functions_4_1_1 functions_4_1_2 functions_4_1_3 functions_4_1_4 is_empty_conjunction  (define (execute exp) (apply (eval (predicate exp) user-initial-environment) (args exp)))\nThe always-true special form always_true syntactic form provides for a query that is always satisfied. It ignores its contents (normally empty) and simply passes through all the frames in the input stream. Always-true is used by the rule-body selector (section ) The rule_body selector (section ) uses always_true always_true operation_table_from_chapter_3 operation_table  (define (always-true ignore frame-stream) frame-stream) (put 'always-true 'qeval always-true) function always_true(ignore, frame_stream) { return frame_stream; } put(\"always_true\", \"evaluate_query\", always_true); The selectors that define the syntax of not and lisp-value javascript_predicate are given in section . Find-assertions , The function find_assertions , simple-query simple_query (section ), takes as input a pattern and a frame. It returns a stream of frames, each extending the given one by a data-base match of the given pattern. It uses fetch-assertions fetch_assertions (section ) to get a stream of all the assertions in the data base that should be checked for a match against the pattern and the frame.",
    "token_count": 290,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_11",
    "chunk_index": 11,
    "content": "The reason for fetch-assertions fetch_@assertions here is that we can often apply simple tests that will eliminate many of the entries in the data base from the pool of candidates for a successful match. The system would still work if we eliminated fetch-assertions fetch_assertions and simply checked a stream of all assertions in the data base, but the computation would be less efficient because we would need to make many more calls to the matcher. find_assertions stream_flatmap check_an_assertion fetch_assertions  (define (find-assertions pattern frame) (stream-flatmap (lambda (datum) (check-an-assertion datum pattern frame)) (fetch-assertions pattern frame))) function find_assertions(pattern, frame) { return stream_flatmap( datum => check_an_assertion(datum, pattern, frame), fetch_assertions(pattern, frame)); }\nCheck-an-assertion The function check_an_assertion takes as arguments a data object (assertion), (an assertion), a pattern, and a frame and returns either a one-element stream containing the extended frame or the-empty-stream null if the match fails. check_an_assertion pattern_match singleton_stream  (define (check-an-assertion assertion query-pat query-frame) (let ((match-result (pattern-match query-pat assertion query-frame))) (if (eq?",
    "token_count": 272,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_12",
    "chunk_index": 12,
    "content": "match-result 'failed) the-empty-stream (singleton-stream match-result)))) function check_an_assertion(assertion, query_pat, query_frame) { const match_result = pattern_match(query_pat, assertion, query_frame); return match_result === \"failed\" ? null : singleton_stream(match_result); } The basic pattern matcher returns either the symbol failed string \"failed\" or an extension of the given frame. The basic idea of the matcher is to check the pattern against the data, element by element, accumulating bindings for the pattern variables. If the pattern and the data object are the same, the match succeeds and we return the frame of bindings accumulated so far. Otherwise, if the pattern is a variable (checked by the function is_variable declared in section ) we extend the current frame by binding the variable to the data, so long as this is consistent with the bindings already in the frame. If the pattern and the data are both pairs, we (recursively) match the car head of the pattern against the car head of the data to produce a frame; in this frame we then match the cdr tail of the pattern against the cdr tail of the data. If none of these cases are applicable, the match fails and we return the symbol failed . string \"failed\" . pattern_match extend_if_consistent variable  (define (pattern-match pat dat frame) (cond ((eq? frame 'failed) 'failed) ((equal? pat dat) frame) ((var?",
    "token_count": 294,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_13",
    "chunk_index": 13,
    "content": "pat) (extend-if-consistent pat dat frame)) ((and (pair? pat) (pair? dat)) (pattern-match (cdr pat) (cdr dat) (pattern-match (car pat) (car dat) frame))) (else 'failed))) function pattern_match(pattern, data, frame) { return frame === \"failed\" ? \"failed\" : equal(pattern, data) ? frame : is_variable(pattern) ? extend_if_consistent(pattern, data, frame) : is_pair(pattern) && is_pair(data) ? pattern_match(tail(pattern), tail(data), pattern_match(head(pattern), head(data), frame)) : \"failed\"; }\nHere is the procedure function that extends a frame by adding a new binding, if this is consistent with the bindings already in the frame: extend_if_consistent make_binding  (define (extend-if-consistent var dat frame) (let ((binding (binding-in-frame var frame))) (if binding (pattern-match (binding-value binding) dat frame) (extend var dat frame)))) function extend_if_consistent(variable, data, frame) { const binding = binding_in_frame(variable, frame); return is_undefined(binding) ? extend(variable, data, frame) : pattern_match(binding_value(binding), data, frame); } If there is no binding for the variable in the frame, we simply add the binding of the variable to the data. Otherwise we match, in the frame, the data against the value of the variable in the frame.",
    "token_count": 299,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_14",
    "chunk_index": 14,
    "content": "If the stored value contains only constants, as it must if it was stored during pattern matching by extend-if-consistent , extend_if_consistent , then the match simply tests whether the stored and new values are the same. If so, it returns the unmodified frame; if not, it returns a failure indication. The stored value may, however, contain pattern variables if it was stored during unification (see section ). The recursive match of the stored pattern against the new data will add or check bindings for the variables in this pattern. For example, suppose we have a frame in which ?x $x is bound to (f ?y) list(\"f\", $y) and ?y $y is unbound, and we wish to augment this frame by a binding of ?x $x to (f b) . list(\"f\", \"b\") . We look up ?x $x and find that it is bound to (f ?y) . list(\"f\", $y) . This leads us to match (f ?y) list(\"f\", $y) against the proposed new value (f b) list(\"f\", \"b\") in the same frame. Eventually this match extends the frame by adding a binding of ?y $y to b . \"b\" . ?X The variable $x remains bound to (f ?y) . list(\"f\", $y) .",
    "token_count": 285,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_15",
    "chunk_index": 15,
    "content": "We never modify a stored binding and we never store more than one binding for a given variable. The procedures functions used by extend-if-consistent extend_if_consistent to manipulate bindings are defined in section . If a pattern contains a dot followed by a pattern variable, the pattern variable matches the rest of the data list (rather than the next element of the data list), just as one would expect with the . Although the pattern matcher we have just implemented doesn t look for dots, it does behave as we want. This is because the Lisp read primitive, which is used by query-driver-loop to read the query and represent it as a list structure, treats dots in a special way. When read sees a car of a cons whose cdr will be the rest of the list) it makes the next item be the cdr of the list structure. For example, the list structure produced by read for the pattern (computer ?type) could be constructed by evaluating the expression (cons 'computer (cons '?type '())) , and that for (computer ?type) could be constructed by evaluating the expression (cons 'computer '?type) . Thus, as pattern-match recursively compares car s and cdr s of a data list and a pattern that had a dot, it eventually matches the variable after the dot (which is a cdr of the pattern) against a sublist of the data list, binding the variable to that list.",
    "token_count": 281,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_16",
    "chunk_index": 16,
    "content": "For example, matching the pattern (computer ?type) against (computer programmer trainee) will match ?type against the list (programmer trainee) . Apply-rules The function apply_rules is the rule analog of find-assertions find_assertions (section ). It takes as input a pattern and a frame, and it forms a stream of extension frames by applying rules from the data base. Stream-flatmap The function stream_flatmap maps apply-a-rule apply_a_@rule down the stream of possibly applicable rules (selected by fetch-rules , fetch_rules , section ) and combines the resulting streams of frames. apply_rules stream_flatmap apply_a_rule fetch_rules  (define (apply-rules pattern frame) (stream-flatmap (lambda (rule) (apply-a-rule rule pattern frame)) (fetch-rules pattern frame))) function apply_rules(pattern, frame) { return stream_flatmap(rule => apply_a_rule(rule, pattern, frame), fetch_rules(pattern, frame)); }\nApply-a-rule applies rules The function apply_a_rule applies a rule using the method outlined in section . It first augments its argument frame by unifying the rule conclusion with the pattern in the given frame. If this succeeds, it evaluates the rule body in this new frame. Before any of this happens, however, the program renames all the variables in the rule with unique new names. The reason for this is to prevent the variables for different rule applications from becoming confused with each other.",
    "token_count": 296,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_17",
    "chunk_index": 17,
    "content": "For instance, if two rules both use a variable named ?x , named $x , then each one may add a binding for ?x $x to the frame when it is applied. These two ?x s $x s have nothing to do with each other, and we should not be fooled into thinking that the two bindings must be consistent. Rather than rename variables, we could devise a more clever environment structure; however, the renaming approach we have chosen here is the most straightforward, even if not the most efficient. (See exercise .) Here is the apply-a-rule apply_a_rule procedure: function: apply_a_rule rename_variables_in unify_match singleton_stream is_rule  (define (apply-a-rule rule query-pattern query-frame) (let ((clean-rule (rename-variables-in rule))) (let ((unify-result (unify-match query-pattern (conclusion clean-rule) query-frame))) (if (eq? unify-result 'failed) the-empty-stream (qeval (rule-body clean-rule) (singleton-stream unify-result)))))) function apply_a_rule(rule, query_pattern, query_frame) { const clean_rule = rename_variables_in(rule); const unify_result = unify_match(query_pattern, conclusion(clean_rule), query_frame); return unify_result === \"failed\" ? null : evaluate_query(rule_body(clean_rule), singleton_stream(unify_result)); } The selectors rule-body rule_body and conclusion that extract parts of a rule are defined in section .",
    "token_count": 291,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_18",
    "chunk_index": 18,
    "content": "We generate unique variable names by associating a unique identifier (such as a number) with each rule application and combining this identifier with the original variable names. For example, if the rule-application identifier is 7, we might change each ?x $x in the rule to ?x-7 $x_7 and each ?y $y in the rule to ?y-7 . $y_7 . ( Make-new-variable (The functions make_new_variable and new-rule-application-id new_rule_application_id are included with the syntax procedures functions in section .) rename_variables_in is_variable_4  (define (rename-variables-in rule) (let ((rule-application-id (new-rule-application-id))) (define (tree-walk exp) (cond ((var? exp) (make-new-variable exp rule-application-id)) ((pair? exp) (cons (tree-walk (car exp)) (tree-walk (cdr exp)))) (else exp))) (tree-walk rule))) function rename_variables_in(rule) { const rule_application_id = new_rule_application_id(); function tree_walk(exp) { return is_variable(exp) ? make_new_variable(exp, rule_application_id) : is_pair(exp) ? pair(tree_walk(head(exp)), tree_walk(tail(exp))) : exp; } return tree_walk(rule); }\nThe procedure function that takes as inputs two patterns and a frame and returns either the extended frame or the symbol failed . string \"failed\" . The unifier is like the pattern matcher except that it is symmetrical variables are allowed on both sides of the match. Unify-match The function unify_match is basically the same as pattern-match , pattern_match , except that there is extra code an extra clause (marked *** below) to handle the case where the object on the right side of the match is a variable. unify_match extend_if_possible variable  (define (unify-match p1 p2 frame) (cond ((eq? frame 'failed) 'failed) ((equal? p1 p2) frame) ((var? p1) (extend-if-possible p1 p2 frame)) ((var? p2) (extend-if-possible p2 p1 frame)) ; *** ((and (pair? p1) (pair? p2)) (unify-match (cdr p1) (cdr p2) (unify-match (car p1) (car p2) frame))) (else 'failed))) function unify_match(p1, p2, frame) { return frame === \"failed\" ? \"failed\" : equal(p1, p2) ? frame : is_variable(p1) ? extend_if_possible(p1, p2, frame) : is_variable(p2) // *** ? extend_if_possible(p2, p1, frame) // *** : is_pair(p1) && is_pair(p2) ? unify_match(tail(p1), tail(p2), unify_match(head(p1), head(p2), frame)) : \"failed\"; }",
    "token_count": 606,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_19",
    "chunk_index": 19,
    "content": "In unification, as in one-sided pattern matching, we want to accept a proposed extension of the frame only if it is consistent with existing bindings. The procedure function extend-if-possible extend_if_possible used in unification is the same as the extend-if-consistent function extend_if_consistent used in pattern matching except for two special checks, marked *** in the program below. In the first case, if the variable we are trying to match is not bound, but the value we are trying to match it with is itself a (different) variable, it is necessary to check to see if the value is bound, and if so, to match its value. If both parties to the match are unbound, we may bind either to the other.",
    "token_count": 150,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_20",
    "chunk_index": 20,
    "content": "The second check deals with attempts to bind a variable to a pattern that includes that variable. Such a situation can occur whenever a variable is repeated in both patterns. Consider, for example, unifying the two patterns (?x ?x) list($x, $x) and (?y $\\langle expression$ $involving$ ?y $\\rangle$ ) list($y, $\\langle$ expression involving $y $\\rangle$ ) in a frame where both ?x $x and ?y $y are unbound. First ?x $x is matched against ?y , $y , making a binding of ?x $x to ?y . $y . Next, the same ?x $x is matched against the given expression involving ?y . $y . Since ?x $x is already bound to ?y , $y , this results in matching ?y $y against the expression. expression. If we think of the unifier as finding a set of values for the pattern variables that make the patterns the same, then these patterns imply instructions to find a ?y $y such that ?y $y is equal to the expression involving ?y . $y . There is no general method for solving such equations, so we We reject such bindings; these cases are recognized by the predicate depends-on? depends_on . (?x ?x) list($x, $x) and (?y ?y) . list($y, $y) . The second attempt to bind ?x $x to ?y $y matches ?y $y (the stored value of ?x (the stored value of $x ) against ?y $y (the new value of ?x ). (the new value of $x ). This is taken care of by the equal? equal clause of unify-match . unify_match . extend_if_possible make_binding depends_on variable  (define (extend-if-possible var val frame) (let ((binding (binding-in-frame var frame))) (cond (binding (unify-match (binding-value binding) val frame)) ((var? val) ; *** (let ((binding (binding-in-frame val frame))) (if binding (unify-match var (binding-value binding) frame) (extend var val frame)))) ((depends-on? val var frame) ; *** 'failed) (else (extend var val frame))))) function extend_if_possible(variable, value, frame) { const binding = binding_in_frame(variable, frame); if (! is_undefined(binding)) { return unify_match(binding_value(binding), value, frame); } else if (is_variable(value)) { // *** const binding = binding_in_frame(value, frame); return ! is_undefined(binding) ? unify_match(variable, binding_value(binding), frame) : extend(variable, value, frame); } else if (depends_on(value, variable, frame)) { // *** return \"failed\"; } else { return extend(variable, value, frame); } }",
    "token_count": 595,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_21",
    "chunk_index": 21,
    "content": "Nevertheless, most logic programming systems today allow cyclic references, by accepting the cyclic data structure as the result of the match. This is justified theoretically using rational trees",
    "token_count": 31,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_22",
    "chunk_index": 22,
    "content": "Depends-on? The function depends_on is a predicate that tests whether an expression proposed to be the value of a pattern variable depends on the variable. This must be done relative to the current frame because the expression may contain occurrences of a variable that already has a value that depends on our test variable. The structure of depends-on? depends_on is a simple recursive tree walk in which we substitute for the values of variables whenever necessary. depends_on variable make_binding  (define (depends-on? exp var frame) (define (tree-walk e) (cond ((var? e) (if (equal? var e) true (let ((b (binding-in-frame e frame))) (if b (tree-walk (binding-value b)) false)))) ((pair? e) (or (tree-walk (car e)) (tree-walk (cdr e)))) (else false))) (tree-walk exp)) function depends_on(expression, variable, frame) { function tree_walk(e) { if (is_variable(e)) { if (equal(variable, e)) { return true; } else { const b = binding_in_frame(e, frame); return is_undefined(b) ? false : tree_walk(binding_value(b)); } } else { return is_pair(e) ? tree_walk(head(e)) || tree_walk(tail(e)) : false; } } return tree_walk(expression); }\nOne important problem in designing logic programming languages is that of arranging things so that as few irrelevant Then, in addition to storing all assertions in one big stream, we store all assertions whose car s are constant symbols in separate streams, in a table indexed by the symbol. To fetch an assertion that may match a pattern, we first check to see if the car of the pattern is a constant symbol. If so, we return (to be tested using the matcher) all the stored assertions that have the same car . If the pattern s car is not a constant symbol, we return all the stored assertions. Cleverer methods could also take advantage of information in the frame, or try also to optimize the case where the car of the pattern is not a constant symbol. We avoid building our criteria for indexing (using the car , handling only the case of constant symbols) into the program; instead we call on predicates and selectors that embody our criteria. We store the assertions in separate streams, one for each kind of information, in a table indexed by the kind. To fetch an assertion that may match a pattern, we return (to be tested using the matcher) all the stored assertions that have the same head (the same kind of information). Cleverer methods could also take advantage of information in the frame. We avoid building our criteria for indexing into the program; instead we call on predicates and selectors that embody our criteria. fetch_assertions get_stream index_key_of  (define THE-ASSERTIONS the-empty-stream) (define (fetch-assertions pattern frame) (if (use-index? pattern) (get-indexed-assertions pattern) (get-all-assertions))) (define (get-all-assertions) THE-ASSERTIONS) (define (get-indexed-assertions pattern) (get-stream (index-key-of pattern) 'assertion-stream)) function fetch_assertions(pattern, frame) { return get_indexed_assertions(pattern); } function get_indexed_assertions(pattern) { return get_stream(index_key_of(pattern), \"assertion-stream\"); } Get-stream The function get_stream looks up a stream in the table and returns an empty stream if nothing is stored there. get_stream operation_table_from_chapter_3 operation_table  (define (get-stream key1 key2) (let ((s (get key1 key2))) (if s s the-empty-stream))) function get_stream(key1, key2) { const s = get(key1, key2); return is_undefined(s) ? null : s; }",
    "token_count": 794,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_23",
    "chunk_index": 23,
    "content": "Rules are stored similarly, using the car of the rule conclusion. Rule conclusions are arbitrary patterns, however, so they differ from assertions in that they can contain variables. A pattern whose car is a constant symbol can match rules whose conclusions start with a variable as well as rules whose conclusions have the same car . Thus, when fetching rules that might match a pattern whose car is a constant symbol we fetch all rules whose conclusions start with a variable as well as those whose conclusions have the same car as the pattern. For this purpose we store all rules whose conclusions start with a variable in a separate stream in our table, indexed by the symbol ? . Rules are stored similarly, using the head of the rule conclusion. A pattern can match rules whose conclusions have the same head. Thus, when fetching rules that might match a pattern we fetch all rules whose conclusions have the same head as the pattern. fetch_rules get_stream index_key_of  (define THE-RULES the-empty-stream) (define (fetch-rules pattern frame) (if (use-index? pattern) (get-indexed-rules pattern) (get-all-rules))) (define (get-all-rules) THE-RULES) (define (get-indexed-rules pattern) (stream-append (get-stream (index-key-of pattern) 'rule-stream) (get-stream '?",
    "token_count": 269,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_24",
    "chunk_index": 24,
    "content": "'rule-stream))) function fetch_rules(pattern, frame) { return get_indexed_rules(pattern); } function get_indexed_rules(pattern) { return get_stream(index_key_of(pattern), \"rule-stream\"); }",
    "token_count": 41,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_25",
    "chunk_index": 25,
    "content": "Add-rule-or-assertion! The function add_rule_or_assertion is used by query-driver-loop query_driver_loop to add assertions and rules to the data base. Each item is stored in the index. add_rule_or_assertion is_rule store_assertion_in_index fetch_assertions fetch_rules  (define (add-rule-or-assertion! assertion) (if (rule? assertion) (add-rule! assertion) (add-assertion! assertion))) (define (add-assertion! assertion) (store-assertion-in-index assertion) (let ((old-assertions THE-ASSERTIONS)) (set! THE-ASSERTIONS (cons-stream assertion old-assertions)) 'ok)) (define (add-rule! rule) (store-rule-in-index rule) (let ((old-rules THE-RULES)) (set! THE-RULES (cons-stream rule old-rules)) 'ok)) function add_rule_or_assertion(assertion) { return is_rule(assertion) ? add_rule(assertion) : add_assertion(assertion); } function add_assertion(assertion) { store_assertion_in_index(assertion); return \"ok\"; } function add_rule(rule) { store_rule_in_index(rule); return \"ok\"; }\nTo actually store an assertion or a rule, we store it in the appropriate stream. store_assertion_in_index operation_table_from_chapter_3 operation_table index_key_of get_stream is_rule  (define (store-assertion-in-index assertion) (if (indexable? assertion) (let ((key (index-key-of assertion))) (let ((current-assertion-stream (get-stream key 'assertion-stream))) (put key 'assertion-stream (cons-stream assertion current-assertion-stream)))))) (define (store-rule-in-index rule) (let ((pattern (conclusion rule))) (if (indexable? pattern) (let ((key (index-key-of pattern))) (let ((current-rule-stream (get-stream key 'rule-stream))) (put key 'rule-stream (cons-stream rule current-rule-stream))))))) function store_assertion_in_index(assertion) { const key = index_key_of(assertion); const current_assertion_stream = get_stream(key, \"assertion-stream\"); put(key, \"assertion-stream\", pair(assertion, () => current_assertion_stream)); } function store_rule_in_index(rule) { const pattern = conclusion(rule); const key = index_key_of(pattern); const current_rule_stream = get_stream(key, \"rule-stream\"); put(key, \"rule-stream\", pair(rule, () => current_rule_stream)); }",
    "token_count": 528,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_26",
    "chunk_index": 26,
    "content": "The following procedures define how the data-base index is used. A pattern (an assertion or a rule conclusion) will be stored in the table if it starts with a variable or a constant symbol. is_indexable variable  (define (indexable? pat) (or (constant-symbol? (car pat)) (var? (car pat)))) The key under which a pattern is stored in the table is either ? (if it starts with a variable) or the constant symbol with which it starts. The key under which a pattern (an assertion or rule conclusion) is stored in the table is the string it starts with. index_key_of variable  (define (index-key-of pat) (let ((key (car pat))) (if (var? key) '? key))) function index_key_of(pattern) { return head(pattern); } The index will be used to retrieve items that might match a pattern if the pattern starts with a constant symbol. use_index  (define (use-index? pat) (constant-symbol? (car pat))) The query system uses a few stream operations that were not presented in chapter .",
    "token_count": 224,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_27",
    "chunk_index": 27,
    "content": "Stream-append-delayed The functions stream_append_delayed and interleave-delayed interleave_delayed are just like stream-append stream_append and interleave (section ), except that they take a delayed argument (like the integral procedure function in section ). This postpones looping in some cases (see exercise ). stream_append_delayed  (define (stream-append-delayed s1 delayed-s2) (if (stream-null? s1) (force delayed-s2) (cons-stream (stream-car s1) (stream-append-delayed (stream-cdr s1) delayed-s2)))) (define (interleave-delayed s1 delayed-s2) (if (stream-null? s1) (force delayed-s2) (cons-stream (stream-car s1) (interleave-delayed (force delayed-s2) (delay (stream-cdr s1)))))) function stream_append_delayed(s1, delayed_s2) { return is_null(s1) ? delayed_s2() : pair(head(s1), () => stream_append_delayed(stream_tail(s1), delayed_s2)); } function interleave_delayed(s1, delayed_s2) { return is_null(s1) ? delayed_s2() : pair(head(s1), () => interleave_delayed(delayed_s2(), () => stream_tail(s1))); }\nStream-flatmap , The function stream_flatmap , which is used throughout the query evaluator to map a procedure function over a stream of frames and combine the resulting streams of frames, is the stream analog of the flatmap procedure function introduced for ordinary lists in section . Unlike ordinary flatmap , however, we accumulate the streams with an interleaving process, rather than simply appending them (see exercises and ). stream_flatmap stream_append_delayed  (define (stream-flatmap proc s) (flatten-stream (stream-map proc s))) (define (flatten-stream stream) (if (stream-null? stream) the-empty-stream (interleave-delayed (stream-car stream) (delay (flatten-stream (stream-cdr stream)))))) function stream_flatmap(fun, s) { return flatten_stream(stream_map(fun, s)); } function flatten_stream(stream) { return is_null(stream) ? null : interleave_delayed( head(stream), () => flatten_stream(stream_tail(stream))); }",
    "token_count": 465,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_28",
    "chunk_index": 28,
    "content": "The evaluator also uses the following simple procedure function to generate a stream consisting of a single element: singleton_stream  (define (singleton-stream x) (cons-stream x the-empty-stream)) function singleton_stream(x) { return pair(x, () => null); }\nWe saw in section that the driver loop first transforms an input string into the JavaScript syntax representation. The input is designed to look like a JavaScript expression so that we can use the parse function from section and also to support JavaScript notation in javascript_predicate . For example, parse('job($x, list(\"computer\", \"wizard\"));'); yields list(\"application\", list(\"name\", \"job\"), list(list(\"name\", \"$x\"), list(\"application\", list(\"name\", \"list\"), list(list(\"literal\", \"computer\"), list(\"literal\", \"wizard\"))))) The tag \"application\" indicates that syntactically, the query would be treated as a function application in JavaScipt. The function unparse transforms the syntax back into a string: unparse(parse('job($x, list(\"computer\", \"wizard\"));')); 'job($x, list(\"computer\", \"wizard\"))' In the query processor, we assumed a more appropriate, query-language-specific, query-language-specific representation of assertions, rules, and queries. The function convert_@to_@query_@syntax transforms the syntax representation into that representation.",
    "token_count": 278,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_29",
    "chunk_index": 29,
    "content": "Using the same example, convert_to_query_syntax(parse('job($x, list(\"computer\", \"wizard\"));')); yields list(\"job\", list(\"name\", \"$x\"), list(\"computer\", \"wizard\")) Query-system functions such as add_rule_or_assertion in section and evaluate_query in section operate on the query-language-specific representation using selectors and predicates such as type , contents , is_rule , and first_conjunct declared below. Figure depicts the three parse , unparse , and convert_to_query_syntax bridge them. Syntax abstraction in the query system. The predicate is_variable is used on the query-language-specific representation during query processing and on the JavaScript syntax representation during instantiation to identify names that start with a dollar sign. char_at that returns a string containing only the character of the given string at the given position. is_variable_2 function is_variable(exp) { return is_name(exp) && char_at(symbol_of_name(exp), 0) === \"$\"; } const is_variable = is_name;\nUnique variables are constructed during rule application (in section ) by means of the following functions. The unique identifier for a rule application is a number, which is incremented each time a rule is applied.",
    "token_count": 239,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_30",
    "chunk_index": 30,
    "content": "is_variable_4 let rule_counter = 0; function new_rule_application_id() { rule_counter = rule_counter + 1; return rule_counter; } function make_new_variable(variable, rule_application_id) { return make_name(symbol_of_name(variable) + \"_\" + stringify(rule_application_id)); }\nThe function convert_to_query_syntax recursively \"pair\" or \"list\" , an (untagged) JavaScript pair or list is built. This means that convert_@to_@query_@syntax interprets applications of the constructors pair and list during the transformation, and processing functions such as pattern_match of section and unify_match of section can operate directly on the intended pairs and lists rather than on the syntax representation generated by the parser. The (one-element) argument list of javascript_predicate remains unprocessed, as explained below. A variable remains unchanged, and a literal is simplified to the primitive value it contains. convert_to_query_syntax functions_4_1_2  function convert_to_query_syntax(exp) { if (is_application(exp)) { const function_symbol = symbol_of_name(function_expression(exp)); if (function_symbol === \"javascript_predicate\") { return pair(function_symbol, arg_expressions(exp)); } else { const processed_args = map(convert_to_query_syntax, arg_expressions(exp)); return function_symbol === \"pair\" ? pair(head(processed_args), head(tail(processed_args))) : function_symbol === \"list\" ?",
    "token_count": 287,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_31",
    "chunk_index": 31,
    "content": "processed_args : pair(function_symbol, processed_args); } } else if (is_variable(exp)) { return exp; } else { // exp is literal return literal_value(exp); } }\nAn exception to this processing is javascript_predicate . Since the instantiated JavaScript syntax representation of its predicate expression is passed to evaluate of section , the original syntax representation coming from parse needs to remain intact in the query-language-specific representation of the expression. In this example of section and(salary($person, $amount), javascript_predicate($amount > 50000)) convert_to_query_syntax produces a data structure in which a JavaScript syntax representation is embedded in a query-language-specific representation: list(\"and\", list(\"salary\", list(\"name\", \"$person\"), list(\"name\", \"$amount\")), list(\"javascript_predicate\", list(\"binary_operator_combination\", \">\", list(\"name\", \"$amount\"), list(\"literal\", 50000)))) In order to evaluate the javascript_predicate subexpression of that processed query, the function javascript_@predicate in section calls the function instantiate_@expression (below) on the embedded JavaScript syntax representation of $amount > 50000 to replace the variable list(\"name\", \"$amount\") by a literal, for example list(\"literal\", 70000) , that represents the primitive value to which $amount is bound, here 70000. The JavaScript evaluator can evaluate the instantiated predicate, which now represents 70000 > 50000 .",
    "token_count": 289,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_32",
    "chunk_index": 32,
    "content": "The function javascript_predicate of section and the driver loop of section call instantiate_@expression on an expression to obtain a copy in which any variable in the expression is replaced by its value in a given frame. The input and result expressions use the JavaScript syntax representation, so any value that results from instantiating a variable needs to be converted from its form in the binding to the JavaScript syntax representation. instantiate make_binding variable express convert  function instantiate_expression(expression, frame) { return is_variable(expression) ? convert(instantiate_term(expression, frame)) : is_pair(expression) ? pair(instantiate_expression(head(expression), frame), instantiate_expression(tail(expression), frame)) : expression; } The function instantiate_term takes a variable, pair, or primitive value as first argument and a frame as second argument and recursively replaces the variables in the first argument by their values in the frame until a primitive value or an unbound variable is reached. When the process encounters a pair, a new pair is constructed whose parts are the instantiated versions of the original parts. For example, if $x is bound to the pair $[\\texttt{\\$y}, 5]$ in a frame $f$ as the result of unification, and $y is in turn bound to 3, the result of applying instantiate_term to list(\"name\", \"$x\") and $f$ is the pair $[3, 5]$ .",
    "token_count": 281,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_33",
    "chunk_index": 33,
    "content": "express function instantiate_term(term, frame) { if (is_variable(term)) { const binding = binding_in_frame(term, frame); return is_undefined(binding) ? term // leave unbound variable as is : instantiate_term(binding_value(binding), frame); } else if (is_pair(term)) { return pair(instantiate_term(head(term), frame), instantiate_term(tail(term), frame)); } else { // $\\texttt{term}$ is a primitive value return term; } } The function convert constructs a JavaScript syntax representation for a variable, pair, or primitive value returned by instantiate_term . A pair in the original becomes an application of JavaScript's pair constructor and a primitive value becomes a literal. convert function convert(term) { return is_variable(term) ? term : is_pair(term) ?",
    "token_count": 158,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_34",
    "chunk_index": 34,
    "content": "make_application(make_name(\"pair\"), list(convert(head(term)), convert(tail(term)))) : // $\\texttt{term}$ is a primitive value make_literal(term); }  append_to_form process_query(`assert( rule(append_to_form(null, $y, $y)))`); process_query(`assert( rule(append_to_form(pair($u, $v), $y, pair($u, $z)), append_to_form($v, $y, $z)))`); process_query(`append_to_form($x, $y, list(\"a\", \"b\", \"c\", \"d\"))`); To illustrate these three functions, consider what happens when the query job($x, list(\"computer\", \"wizard\")) whose JavaScript syntax representation is given at the beginning of section , is processed by the driver loop. Let's say a frame $g$ of the result stream binds the variable $x to the pair $[\\texttt{\"Bitdiddle\"}, \\texttt{\\$y}]$ and the variable $y to the pair $[\\texttt{\"Ben\"}, \\texttt{null}]$ .",
    "token_count": 228,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_35",
    "chunk_index": 35,
    "content": "Then instantiate_term(list(\"name\", \"$\\$$x\"), $g$) returns the list list(\"Bitdiddle\", \"Ben\") which convert transforms into list(\"application\", list(\"name\", \"pair\"), list(list(\"literal\", \"Bitdiddle\"), list(\"application\", list(\"name\", \"pair\"), list(list(\"literal\", \"Ben\"), list(\"literal\", null))))) The result of instantiate_expression applied to the JavaScript syntax representation of the query and the frame $g$ is: list(\"application\", list(\"name\", \"job\"), list(list(\"application\", list(\"name\", \"pair\"), list(list(\"literal\", \"Bitdiddle\"), list(\"application\", list(\"name\", \"pair\"), list(list(\"literal\", \"Ben\"), list(\"literal\", null))))), list(\"application\", list(\"name\", \"list\"), list(list(\"literal\", \"computer\"), list(\"literal\", \"wizard\"))))) The driver loop unparses this representation and displays it as: 'job(list(\"Bitdiddle\", \"Ben\"), list(\"computer\", \"wizard\"))'\nThe function unparse transforms a component given in the JavaScript syntax representation into a string by applying the syntax rules of section . We describe unparse only for those kinds of expressions that appear in the examples of section , leaving statements and the remaining kinds of expressions as exercise .",
    "token_count": 272,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_36",
    "chunk_index": 36,
    "content": "A literal is transformed by stringify ing its value, and a name is transformed into its unparse is_list_construction element_expressions comma_separated function unparse(exp) { return is_literal(exp) ? stringify(literal_value(exp)) : is_name(exp) ? symbol_of_name(exp) : is_list_construction(exp) ? unparse(make_application(make_name(\"list\"), element_expressions(exp))) : is_application(exp) && is_name(function_expression(exp)) ? symbol_of_name(function_expression(exp)) + \"(\" + comma_separated(map(unparse, arg_expressions(exp))) + \")\" : is_binary_operator_combination(exp) ? \"(\" + unparse(first_operand(exp)) + \" \" + operator_symbol(exp) + \" \" + unparse(second_operand(exp)) + \")\" unparsing other kinds of JavaScript components : error(exp, \"unknown syntax -- unparse\"); } function has_char(x, c) { let found = false; let i = 0; while (char_at(x, i) !== undefined) { found = found || char_at(x, i) === c; i = i + 1; } return found; } function better_stringify(x) { return is_string(x) && ! has_char(x, \"'\") ? \"'\" + x + \"'\" : stringify(x); } function unparse(exp) { return is_literal(exp) ? better_stringify(literal_value(exp)) : is_name(exp) ?",
    "token_count": 286,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_37",
    "chunk_index": 37,
    "content": "symbol_of_name(exp) : is_list_construction(exp) ? unparse(make_application(make_name(\"list\"), element_expressions(exp))) : is_application(exp) && is_name(function_expression(exp)) ? symbol_of_name(function_expression(exp)) + \"(\" + comma_separated(map(unparse, arg_expressions(exp))) + \")\" : is_binary_operator_combination(exp) ? \"(\" + unparse(first_operand(exp)) + \" \" + operator_symbol(exp) + \" \" + unparse(second_operand(exp)) + \")\" : error(exp, \"unknown syntax -- unparse\"); } comma_separated function comma_separated(strings) { return accumulate((s, acc) => s + (acc === \"\" ? \"\" : \", \" + acc), \"\", strings); } The function unparse would work fine without the clause : is_list_construction(exp) ? unparse(make_application(make_name(\"list\"), element_expressions(exp))) but the output string would be unnecessarily verbose in cases where pattern variables are instantiated by lists.",
    "token_count": 199,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_38",
    "chunk_index": 38,
    "content": "In the example above, where processing the query job($x, list(\"computer\", \"wizard\")) yields a frame that binds $x to $[\\texttt{\"Bitdiddle\"}, [\\texttt{\"Ben\"}, \\texttt{null}]]$ , unparse produces 'job(list(\"Bitdiddle\", \"Ben\"), list(\"computer\", \"wizard\"))' However, without the clause it would produce 'job(pair(\"Bitdiddle\", pair(\"Ben\", null)), list(\"computer\", \"wizard\"))' which explicitly constructs the two pairs that make up the first list. To achieve the more concise formatting used throughout section , we inserted the clause to check if the expression constructs a list, in which case we format it as a single application of list to the list of element expressions that we extract from the expression. A list construction is the literal null or an application of pair whose second argument is itself a list construction. is_list_construction function is_list_construction(exp) { return (is_literal(exp) && is_null(literal_value(exp))) || (is_application(exp) && is_name(function_expression(exp)) && symbol_of_name(function_expression(exp)) === \"pair\" && is_list_construction(head(tail(arg_expressions(exp))))); } Extracting the element expressions from a given list construction amounts to collecting the first arguments of applications of pair until the literal null is reached. element_expressions function element_expressions(list_constr) { return is_literal(list_constr) ?",
    "token_count": 299,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_39",
    "chunk_index": 39,
    "content": "null // $\\texttt{list\\char`_constr}$ is literal $\\texttt{null}$ : // $\\texttt{list\\char`_constr}$ is application of $\\texttt{pair}$ pair(head(arg_expressions(list_constr)), element_expressions( head(tail(arg_expressions(list_constr))))); } function element_expressions(list_constr) { return is_literal(list_constr) ? null // list_constr is literal null : // list_constr is application of pair pair(head(arg_expressions(list_constr)), element_expressions( head(tail(arg_expressions(list_constr))))); }\nThe functions type and contents , used by evaluate_query (section ), specify that a syntactic form of a query-language-specific representation is identified by the string in its head. They are the same as the type_tag and contents functions in section , except for the error message. type  functions_4_1_2 function type(exp) { return is_pair(exp) ? head(exp) : error(exp, \"unknown expression type\"); } function contents(exp) { return is_pair(exp) ?",
    "token_count": 227,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_40",
    "chunk_index": 40,
    "content": "tail(exp) : error(exp, \"unknown expression contents\"); }\nThe following functions, used by query_driver_loop (in section ), specify that rules and assertions are added to the data base by an assert command, which the function convert_to_query_syntax transforms into a pair of the form [\"assert\", rule-or-assertion ] : is_assertion type  function is_assertion(exp) { return type(exp) === \"assert\"; } function assertion_body(exp) { return head(contents(exp)); }",
    "token_count": 99,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_41",
    "chunk_index": 41,
    "content": "Here are the declarations of the predicates and selectors for the and , or , not , and javascript_predicate syntactic forms (section ): is_empty_conjunction  function is_empty_conjunction(exps) { return is_null(exps); } function first_conjunct(exps) { return head(exps); } function rest_conjuncts(exps) { return tail(exps); } function is_empty_disjunction(exps) { return is_null(exps); } function first_disjunct(exps) { return head(exps); } function rest_disjuncts(exps) { return tail(exps); } function negated_query(exps) { return head(exps); } function javascript_predicate_expression(exps) { return head(exps); }\nThe following three functions define the query-language-specific representation of rules: is_rule functions_4_1_2  function is_rule(assertion) { return is_tagged_list(assertion, \"rule\"); } function conclusion(rule) { return head(tail(rule)); } function rule_body(rule) { return is_null(tail(tail(rule))) ? list(\"always_true\") : head(tail(tail(rule))); }\nType and contents , used by qeval (section ), specify that a special form is identified by the symbol in its car . They are the same as the type-tag and contents procedures in section , except for the error message. type_scheme  functions_4_1_2 (define (type exp) (if (pair? exp) (car exp) (error \"Unknown expression TYPE\" exp))) (define (contents exp) (if (pair? exp) (cdr exp) (error \"Unknown expression CONTENTS\" exp)))",
    "token_count": 345,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_42",
    "chunk_index": 42,
    "content": "The following procedures, used by query-driver-loop (in section ), specify that rules and assertions are added to the data base by expressions of the form (assert! rule-or-assertion) : is_assertion_scheme type  (define (assertion-to-be-added? exp) (eq? (type exp) 'assert!)) (define (add-assertion-body exp) (car (contents exp)))",
    "token_count": 83,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_43",
    "chunk_index": 43,
    "content": "Here are the syntax definitions for the and , or , not , and lisp-value special forms (section ): is_empty_conjunction_scheme  (define (empty-conjunction? exps) (null? exps)) (define (first-conjunct exps) (car exps)) (define (rest-conjuncts exps) (cdr exps)) (define (empty-disjunction? exps) (null? exps)) (define (first-disjunct exps) (car exps)) (define (rest-disjuncts exps) (cdr exps)) (define (negated-query exps) (car exps)) (define (predicate exps) (car exps)) (define (args exps) (cdr exps))\nThe following three procedures define the syntax of rules: is_rule_scheme functions_4_1_2  (define (rule? statement) (tagged-list? statement 'rule)) (define (conclusion rule) (cadr rule)) (define (rule-body rule) (if (null? (cddr rule)) '(always-true) (caddr rule)))\nQuery-driver-loop (section ) calls query-syntax-process to transform pattern variables in the expression, which have the form ?symbol , into the internal format (? symbol) . That is to say, a pattern such as (job ?x ?y) is actually represented internally by the system as (job (? x) (? y)) . This increases the efficiency of query processing, since it means that the system can check to see if an expression is a pattern variable by checking whether the car of the expression is the symbol ? , rather than having to extract characters from the symbol. The syntax transformation is accomplished by the following procedure: query_process_scheme (define (query-syntax-process exp) (map-over-symbols expand-question-mark exp)) (define (map-over-symbols proc exp) (cond ((pair? exp) (cons (map-over-symbols proc (car exp)) (map-over-symbols proc (cdr exp)))) ((symbol? exp) (proc exp)) (else exp))) (define (expand-question-mark symbol) (let ((chars (symbol->string symbol))) (if (string=? (substring chars 0 1) \"?\") (list '? (string->symbol (substring chars 1 (string-length chars)))) symbol)))",
    "token_count": 486,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_44",
    "chunk_index": 44,
    "content": "Once the variables are transformed in this way, the variables in a pattern are lists starting with ? , and the constant symbols (which need to be recognized for data-base indexing, section ) are just the symbols. is_var_scheme functions_4_1_2  (define (var? exp) (tagged-list? exp '?)) (define (constant-symbol? exp) (symbol? exp))\nUnique variables are constructed during rule application (in section ) by means of the following procedures. The unique identifier for a rule application is a number, which is incremented each time a rule is applied. new_rule_application_id  (define rule-counter 0) (define (new-rule-application-id) (set! rule-counter (+ 1 rule-counter)) rule-counter) (define (make-new-variable var rule-application-id) (cons '? (cons rule-application-id (cdr var))))",
    "token_count": 177,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Logic Programming",
    "subsection": "Implementing the Query System",
    "chunk_id": "chapter4_chunks_Implementing_the_Query_System_45",
    "chunk_index": 45,
    "content": "When query-driver-loop instantiates the query to print the answer, it converts any unbound pattern variables back to the right form for printing, using contract_question_mark_scheme (define (contract-question-mark variable) (string->symbol (string-append \"?\" (if (number? (cadr variable)) (string-append (symbol->string (caddr variable)) \"-\" (number->string (cadr variable))) (symbol->string (cadr variable))))))\nFrames are represented as lists of bindings, which are variable-value pairs: make_binding operation_table_from_chapter_3 operation_table  (define (make-binding variable value) (cons variable value)) (define (binding-variable binding) (car binding)) (define (binding-value binding) (cdr binding)) (define (binding-in-frame variable frame) (assoc variable frame)) (define (extend variable value frame) (cons (make-binding variable value) frame)) function make_binding(variable, value) { return pair(variable, value); } function binding_variable(binding) { return head(binding); } function binding_value(binding) { return tail(binding); } function binding_in_frame(variable, frame) { return assoc(variable, frame); } function extend(variable, value, frame) { return pair(make_binding(variable, value), frame); }",
    "token_count": 257,
    "source_files": [
      "subsection4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Metalinguistic Abstraction",
    "subsection": "Logic Programming",
    "chunk_id": "chapter4_chunks_Logic_Programming_1",
    "chunk_index": 1,
    "content": "In chapter we stressed that computer science deals with\nMost programming languages, including Lisp, JavaScript, are organized around computing the values of mathematical functions. Expression-oriented languages (such as Lisp, Fortran, Algol and JavaScript) (such as Lisp, C, Python, and JavaScript) capitalize on the pun that an expression that describes the value of a function may also be interpreted as a means of computing that value. Because of this, most programming languages are strongly biased toward unidirectional computations (computations with well-defined inputs and outputs). There are, however, radically different programming languages that relax this bias. We saw one such example in section , where the objects of computation were arithmetic constraints. In a constraint system the direction and the order of computation are not so well specified; in carrying out a computation the system must therefore provide more detailed how to knowledge than would be the case with an ordinary arithmetic computation. This does not mean, however, that the user is released altogether from the responsibility of providing imperative knowledge. There are many constraint networks that implement the same set of constraints, and the user must choose from the set of mathematically equivalent networks a suitable network to specify a particular computation. The nondeterministic program evaluator of section also moves away from the view that programming is about constructing algorithms for computing unidirectional functions. In a nondeterministic language, expressions can have more than one value, and, as a result, the computation is dealing with unification .",
    "token_count": 295,
    "source_files": [
      "section4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Metalinguistic Abstraction",
    "subsection": "Logic Programming",
    "chunk_id": "chapter4_chunks_Logic_Programming_2",
    "chunk_index": 2,
    "content": "This approach, when it works, can be a very what is fact can be used to solve a number of different problems that would have different how to components. As an example, consider the append operation, which takes two lists as arguments and combines their elements to form a single list. In a procedural language such as Lisp, JavaScript, we could define append in terms of the basic list constructor cons , pair , as we did in section : (define (append x y) (if (null? x) y (cons (car x) (append (cdr x) y)))) function append(x, y) { return is_null(x) ? y : pair(head(x), append(tail(x), y)); } This procedure function can be regarded as a translation into Lisp JavaScript of the following two rules, the first of which covers the case where the first list is empty and the second of which handles the case of a nonempty list, which is a cons pair of two parts: For any list y , the empty list and y append to form y . For any u , v , y , and z , (cons u v) pair(u, v) and y append to form (cons u z) pair(u, z) if v and y append to form z . Using the append procedure, function, we can answer questions such as Find the append of (a b) list(\"a\", \"b\") and (c d) . list(\"c\", \"d\") .",
    "token_count": 300,
    "source_files": [
      "section4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Metalinguistic Abstraction",
    "subsection": "Logic Programming",
    "chunk_id": "chapter4_chunks_Logic_Programming_3",
    "chunk_index": 3,
    "content": "But the same two rules are also sufficient for answering the following sorts of questions, which the procedure function can t answer: Find a list y that append s with (a b) list(\"a\", \"b\") to produce (a b c d) . list(\"a\", \"b\", \"c\", \"d\") . Find all x and y that append to form (a b c d) . list(\"a\", \"b\", \"c\", \"d\") . In a append procedure function by stating the two rules about append given above. How to knowledge is provided automatically by the interpreter to allow this single pair of rules to be used to answer all three types of questions about append . Contemporary logic programming languages (including the one we implement here) have substantial deficiencies, in that their general how to methods can lead them into spurious infinite loops or other undesirable behavior. Logic programming is an active field of research in computer science. Earlier in this chapter we explored the technology of implementing interpreters and described the elements that are essential to an interpreter for a Lisp-like JavaScript-like language (indeed, to an interpreter for any conventional language). Now we will apply these ideas to discuss an interpreter for a logic programming language. We call this language the query language , because it is very useful for retrieving information from data bases by formulating queries , or questions, expressed in the language.",
    "token_count": 277,
    "source_files": [
      "section4.xml"
    ]
  },
  {
    "chapter_file": "chapter4_chunks.json",
    "section": "Metalinguistic Abstraction",
    "subsection": "Logic Programming",
    "chunk_id": "chapter4_chunks_Logic_Programming_4",
    "chunk_index": 4,
    "content": "Even though the query language is very different from Lisp, JavaScript, we will find it convenient to describe the language in terms of the same general framework we have been using all along: as a collection of primitive elements, together with means of combination that enable us to combine simple elements to create more complex elements and means of abstraction that enable us to regard complex elements as single conceptual units. An interpreter for a logic programming language is considerably more complex than an interpreter for a language like Lisp. JavaScript. Nevertheless, we will see that our . In particular, there will be an evaluate part that classifies expressions according to type and an apply part that implements the language s abstraction mechanism (procedures (functions in the case of Lisp, JavaScript, and rules in the case of logic programming). Also, a central role is played in the implementation by a frame data structure, which determines the correspondence between symbols and their associated values. One additional interesting aspect of our query-language implementation is that we make substantial use of streams, which were introduced in chapter .",
    "token_count": 206,
    "source_files": [
      "section4.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": null,
    "subsection": "Computing with Register Machines",
    "chunk_id": "chapter5_chunks_Computing_with_Register_Machines_1",
    "chunk_index": 1,
    "content": "We began this book by studying processes and by describing processes in terms of procedures functions written in Lisp. JavaScript. To explain the meanings of these procedures, functions, we used a succession of models of evaluation: the substitution model of chapter , the environment model of chapter , and the metacircular evaluator of chapter . Our examination of the metacircular evaluator, in particular, dispelled much of the mystery of how Lisp-like languages are interpreted. JavaScript-like languages are interpreted. But even the metacircular evaluator leaves important questions unanswered, because it fails to elucidate the mechanisms of control in a Lisp JavaScript system. For instance, the evaluator does not explain how the evaluation of a subexpression manages to return a value to the expression that uses this value , nor does the evaluator explain how some recursive procedures generate iterative processes (that is, are evaluated using constant space) whereas other recursive procedures generate recursive processes . These questions remain unanswered because the metacircular evaluator is itself a Lisp program and hence inherits the control structure of the underlying Lisp system. In order to provide a more complete description of the control structure of the Lisp evaluator, we must work at a more primitive level than Lisp itself. Also, the evaluator does not explain how some recursive functions can generate iterative processes (that is, be evaluated using constant space) whereas other recursive functions will generate recursive processes. In this chapter we We will describe processes in terms of the step-by-step operation of a traditional computer.",
    "token_count": 291,
    "source_files": [
      "chapter5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": null,
    "subsection": "Computing with Register Machines",
    "chunk_id": "chapter5_chunks_Computing_with_Register_Machines_2",
    "chunk_index": 2,
    "content": "Such a computer, or register machine , sequentially executes instructions that manipulate the contents of a fixed set of storage elements called registers . A typical register-machine instruction applies a primitive operation to the contents of some registers and assigns the result to another register. Our descriptions of processes executed by register machines will look very much like machine-language programs for traditional computers. However, instead of focusing on the machine language of any particular computer, we will examine several Lisp JavaScript procedures functions and design a specific register machine to execute each procedure. function. Thus, we will approach our task from the perspective of a hardware architect rather than that of a machine-language computer programmer. In designing register machines, we will develop mechanisms for implementing important programming constructs such as recursion. We will also present a language for describing designs for register machines. In section we will implement a Lisp JavaScript program that uses these descriptions to simulate the machines we design. Most of the primitive operations of our register machines are very simple. For example, an operation might add the numbers fetched from two registers, producing a result to be stored into a third register. Such an operation can be performed by easily described hardware. In order to deal with list structure, however, we will also use the memory operations car , head , cdr , tail , and cons , pair , which require an elaborate storage-allocation mechanism. In section we study their implementation in terms of more elementary operations.",
    "token_count": 279,
    "source_files": [
      "chapter5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": null,
    "subsection": "Computing with Register Machines",
    "chunk_id": "chapter5_chunks_Computing_with_Register_Machines_3",
    "chunk_index": 3,
    "content": "In section , after we have accumulated experience formulating simple procedures functions as register machines, we will design a machine that carries out the algorithm described by the metacircular evaluator of section . This will fill in the gap in our understanding of how Scheme expressions JavaScript programs are interpreted, by providing an explicit model for the mechanisms of control in the evaluator. In section we will study a simple compiler that translates Scheme JavaScript programs into sequences of instructions that can be executed directly with the registers and operations of the evaluator register machine.",
    "token_count": 102,
    "source_files": [
      "chapter5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": "Compilation",
    "subsection": "An Example of Compiled Code",
    "chunk_id": "chapter5_chunks_An_Example_of_Compiled_Code_1",
    "chunk_index": 1,
    "content": "Now that we have seen all the elements of the compiler, let us examine an example of compiled code to see how things fit together. We will compile the definition declaration of a recursive factorial factorial procedure function by calling compile : by passing as first argument to compile the result of applying parse to a string representation of the program (here using ` $\\ldots$ ` , which work like single and double quotation marks but allow the string to span multiple lines): (compile '(define (factorial n) (if (= n 1) 1 (* (factorial (- n 1)) n))) 'val 'next) compile(parse(` function factorial(n) { return n === 1 ? 1 : factorial(n - 1) * n; } `), \"val\", \"next\"); We have specified that the value of the define expression declaration should be placed in the val register. We don t care what the compiled code does after executing the define , declaration, so our choice of next \"next\" as the linkage descriptor is arbitrary. Compile determines that the expression is a definition, so it The function compile determines that it was given a function declaration, so it transforms it to a constant declaration and then calls compile-definition to compile compile_declaration .",
    "token_count": 250,
    "source_files": [
      "subsection5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": "Compilation",
    "subsection": "An Example of Compiled Code",
    "chunk_id": "chapter5_chunks_An_Example_of_Compiled_Code_2",
    "chunk_index": 2,
    "content": "This compiles code to compute the value to be assigned (targeted to val ), followed by code to install the definition, declaration, followed by code to put the value of the define (which is the symbol ok ) declaration (which is the value undefined ) into the target register, followed finally by the linkage code. Env The env register is preserved around the computation of the value, because it is needed in order to install the definition. declaration. Because the linkage is next , \"next\" , there is no linkage code in this case. The skeleton of the compiled code is thus $\\langle save$ env $if\\ modified\\ by\\ code\\ to\\ compute\\ value\\rangle$ $\\langle compilation\\ of\\ definition\\ value, target$ val$, linkage$ next$\\rangle$ $\\langle restore$ env $if\\ saved\\ above\\rangle$ (perform (op define-variable!) (const factorial) (reg val) (reg env)) (assign val (const ok)) save env if modified by code to compute value compilation of declaration value, target val , linkage \"next\" restore env if saved above perform(list(op(\"assign_symbol_value\"), constant(\"factorial\"), reg(\"val\"), reg(\"env\"))), assign(\"val\", constant(undefined))\nThe expression that is to be compiled to produce the value for the variable name factorial is a lambda lambda expression whose value is the procedure function that computes factorials.",
    "token_count": 286,
    "source_files": [
      "subsection5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": "Compilation",
    "subsection": "An Example of Compiled Code",
    "chunk_id": "chapter5_chunks_An_Example_of_Compiled_Code_3",
    "chunk_index": 3,
    "content": "Compile The function compile handles this by calling compile-lambda , compile_lambda_expression , which compiles the procedure function body, labels it as a new entry point, and generates the instruction that will combine the procedure function body at the new entry point with the runtime environment and assign the result to val . The sequence then skips around the compiled procedure function code, which is inserted at this point. The procedure function code itself begins by extending the procedure s definition function s declaration environment by a frame that binds the formal parameter n to the procedure function argument. Then comes the actual procedure function body. Since this code for the value of the variable name doesn t modify the env register, the optional save and restore shown above aren t generated. (The procedure function code at entry2 entry1 isn t executed at this point, so its use of env is irrelevant.) Therefore, the skeleton for the compiled code becomes (assign val (op make-compiled-procedure) (label entry2) (reg env)) (goto (label after-lambda1)) entry2 (assign env (op compiled-procedure-env) (reg proc)) (assign env (op extend-environment) (const (n)) (reg argl) (reg env)) $\\langle compilation\\ of\\ procedure\\ body\\rangle$ after-lambda1 (perform (op define-variable!)",
    "token_count": 269,
    "source_files": [
      "subsection5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": "Compilation",
    "subsection": "An Example of Compiled Code",
    "chunk_id": "chapter5_chunks_An_Example_of_Compiled_Code_4",
    "chunk_index": 4,
    "content": "(const factorial) (reg val) (reg env)) (assign val (const ok)) $\\texttt{ }\\texttt{ }$assign(\"val\", list(op(\"make_compiled_function\"), label(\"entry1\"), reg(\"env\"))), go_to(label(\"after_lambda2\")), \"entry1\", assign(\"env\", list(op(\"compiled_function_env\"), reg(\"fun\"))), assign(\"env\", list(op(\"extend_environment\"), constant(list(\"n\")), reg(\"argl\"), reg(\"env\"))), compilation of function body \"after_lambda2\", perform(list(op(\"assign_symbol_value\"), constant(\"factorial\"), reg(\"val\"), reg(\"env\"))), assign(\"val\", constant(undefined))\nA procedure function body is always compiled (by compile-lambda-body ) compile_lambda_body ) as a sequence with target val and linkage return . \"next\" . The sequence body in this case consists of a single if expression: return statement: (if (= n 1) 1 (* (factorial (- n 1)) n)) return n === 1 ? 1 : factorial(n - 1) * n; The function compile_return_statement generates code to revert the stack using the marker and to restore the continue register, and then compiles the return expression with target val and linkage \"return\" , because its value is to be returned from the function.",
    "token_count": 275,
    "source_files": [
      "subsection5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": "Compilation",
    "subsection": "An Example of Compiled Code",
    "chunk_id": "chapter5_chunks_An_Example_of_Compiled_Code_5",
    "chunk_index": 5,
    "content": "Compile-if The return expression is a conditional expression, for which compile_conditional generates code that first computes the predicate (targeted to val ), then checks the result and branches around the true branch if the predicate is false. Env Registers env and continue are preserved around the predicate code, since they may be needed for the rest of the if conditional expression. Since the if expression is the final expression (and only expression) in the sequence making up the procedure body, its target is val and its linkage is return , so the The true and false branches are both compiled with target val and linkage return . \"return\" . (That is, the value of the conditional, which is the value computed by either of its branches, is the value of the procedure.) function.) $\\langle save$ continue, env $if\\ modified\\ by\\ predicate\\ and\\ needed\\ by\\ branches\\rangle$ $\\langle compilation\\ of\\ predicate, target$ val$,\\ linkage$ next$\\rangle$ $\\langle restore$ continue, env $if\\ saved\\ above\\rangle$ (test (op false?)",
    "token_count": 220,
    "source_files": [
      "subsection5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": "Compilation",
    "subsection": "An Example of Compiled Code",
    "chunk_id": "chapter5_chunks_An_Example_of_Compiled_Code_6",
    "chunk_index": 6,
    "content": "(reg val)) (branch (label false-branch4)) true-branch5 $\\langle compilation\\ of\\ true\\ branch, target$ val$,\\ linkage$ return$\\rangle$ false-branch4 $\\langle compilation\\ of\\ false\\ branch, target$ val$,\\ linkage$ return$\\rangle$ after-if3 $\\texttt{ }\\texttt{ }$revert_stack_to_marker(), restore(\"continue\"), save continue , env if modified by predicate and needed by branches compilation of predicate, target val , linkage \"next\" restore continue , env if saved above test(list(op(\"is_falsy\"), reg(\"val\"))), branch(label(\"false_branch4\")), \"true_branch3\", compilation of true branch, target val , linkage \"return\" \"false_branch4\", compilation of false branch, target val , linkage \"return\" \"after_cond5\",",
    "token_count": 174,
    "source_files": [
      "subsection5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": "Compilation",
    "subsection": "An Example of Compiled Code",
    "chunk_id": "chapter5_chunks_An_Example_of_Compiled_Code_7",
    "chunk_index": 7,
    "content": "The predicate (= n 1) n === 1 is a procedure call. function application (after transformation of the operator combination). This looks up the operator (the symbol = ) function expression (the symbol \"===\" ) and places this value in proc . fun . It then assembles the arguments 1 and the value of n into argl . Then it tests whether proc fun contains a primitive or a compound procedure, function, and dispatches to a primitive branch or a compound branch accordingly. Both branches resume at the after-call after_call label. The compound branch must set up continue to jump past the primitive branch and push a marker to the stack to match the revert operation in the compiled return statement of the function. The requirements to preserve registers around the evaluation of the operator and operands function and argument expressions don t result in any saving of registers, because in this case those evaluations don t modify the registers in question. (assign proc (op lookup-variable-value) (const =) (reg env)) (assign val (const 1)) (assign argl (op list) (reg val)) (assign val (op lookup-variable-value) (const n) (reg env)) (assign argl (op cons) (reg val) (reg argl)) (test (op primitive-procedure?) (reg proc)) (branch (label primitive-branch17)) compiled-branch16 (assign continue (label after-call15)) (assign val (op compiled-procedure-entry) (reg proc)) (goto (reg val)) primitive-branch17 (assign val (op apply-primitive-procedure) (reg proc) (reg argl)) after-call15 $\\texttt{ }\\texttt{ }$assign(\"fun\", list(op(\"lookup_symbol_value\"), constant(\"===\"), reg(\"env\"))), assign(\"val\", constant(1)), assign(\"argl\", list(op(\"list\"), reg(\"val\"))), assign(\"val\", list(op(\"lookup_symbol_value\"), constant(\"n\"), reg(\"env\"))), assign(\"argl\", list(op(\"pair\"), reg(\"val\"), reg(\"argl\"))), test(list(op(\"is_primitive_function\"), reg(\"fun\"))), branch(label(\"primitive_branch6\")), \"compiled_branch7\", assign(\"continue\", label(\"after_call8\")), save(\"continue\"), push_marker_to_stack(), assign(\"val\", list(op(\"compiled_function_entry\"), reg(\"fun\"))), go_to(reg(\"val\")), \"primitive_branch6\", assign(\"val\", list(op(\"apply_primitive_function\"), reg(\"fun\"), reg(\"argl\"))), \"after_call8\",",
    "token_count": 526,
    "source_files": [
      "subsection5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": "Compilation",
    "subsection": "An Example of Compiled Code",
    "chunk_id": "chapter5_chunks_An_Example_of_Compiled_Code_8",
    "chunk_index": 8,
    "content": "The true branch, which is the constant 1, compiles (with target val and linkage return ) \"return\" ) to (assign val (const 1)) (goto (reg continue)) $\\texttt{ }\\texttt{ }$assign(\"val\", constant(1)), go_to(reg(\"continue\")), The code for the false branch is another procedure function call, where the procedure function is the value of the symbol * , \"*\" , and the arguments are n and the result of another procedure function call (a call to factorial ). Each of these calls sets up proc fun and argl and its own primitive and compound branches. Figure shows the complete compilation of the definition declaration of the factorial procedure. function. Notice that the possible save and restore of continue and env around the predicate, shown above, are in fact generated, because these registers are modified by the procedure function call in the predicate and needed for the procedure function call and the return \"return\" linkage in the branches.",
    "token_count": 198,
    "source_files": [
      "subsection5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": "Computing with Register Machines",
    "subsection": "Compilation",
    "chunk_id": "chapter5_chunks_Compilation_1",
    "chunk_index": 1,
    "content": "The explicit-control evaluator of section is a register machine whose controller interprets Scheme JavaScript programs. In this section we will see how to run Scheme JavaScript programs on a register machine whose controller is not a Scheme JavaScript interpreter. The explicit-control evaluator machine is it can carry out any computational process that can be described in Scheme. JavaScript. The evaluator s controller orchestrates the use of its data paths to perform the desired computation. Thus, the evaluator s data paths are universal: They are sufficient to perform any computation we desire, given an appropriate controller. Commercial native language of the machine, or simply machine language . Programs written in machine language are sequences of instructions that use the machine s data paths. For example, the s instruction sequence can be thought of as a machine-language program for a general-purpose computer rather than as the controller for a specialized interpreter machine. There are two common strategies for bridging the gap between higher-level languages and register-machine languages. The explicit-control evaluator illustrates the strategy of interpretation. An interpreter written in the native language of a machine configures the machine to execute programs written in a language (called the source language ) that may differ from the native language of the machine performing the evaluation. The primitive procedures functions of the source language are implemented as a library of subroutines written in the native language of the given machine. A program to be interpreted (called the source program ) is represented as a data structure. The interpreter traverses this data structure, analyzing the source program.",
    "token_count": 297,
    "source_files": [
      "section5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": "Computing with Register Machines",
    "subsection": "Compilation",
    "chunk_id": "chapter5_chunks_Compilation_2",
    "chunk_index": 2,
    "content": "As it does so, it simulates the intended behavior of the source program by calling appropriate primitive subroutines from the library. In this section, we explore the alternative strategy of compilation . A compiler for a given source language and machine translates a source program into an equivalent program (called the object program ) written in the machine s native language. The compiler that we implement in this section translates programs written in Scheme JavaScript into sequences of instructions to be executed using the explicit-control evaluator machine s data paths. Compared with interpretation, compilation can provide a great increase in the efficiency of program execution, as we will explain below in the overview of the compiler. On the other hand, an interpreter provides a more powerful environment for interactive program development and debugging, because the source program being executed is available at run time to be examined and modified. In addition, because the entire library of primitives is present, new programs can be constructed and added to the system during debugging. In view of the complementary advantages of compilation and interpretation, modern program-development environments pursue a mixed strategy. Lisp interpreters These systems are generally organized so that interpreted procedures functions and compiled procedures functions can call each other. This enables a programmer to compile those parts of a program that are assumed to be debugged, thus gaining the efficiency advantage of compilation, while retaining the interpretive mode of execution for those parts of the program that are in the flux of interactive development and debugging.",
    "token_count": 284,
    "source_files": [
      "section5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": "Computing with Register Machines",
    "subsection": "Compilation",
    "chunk_id": "chapter5_chunks_Compilation_3",
    "chunk_index": 3,
    "content": "In section , after we have implemented the compiler, we will show how to interface it with our interpreter to produce an integrated interpreter-compiler development system. Our compiler is much like our interpreter, both in its structure and in the function it performs. Accordingly, the mechanisms used by the compiler for analyzing expressions components will be similar to those used by the interpreter. Moreover, to make it easy to interface compiled and interpreted code, we will design the compiler to generate code that obeys the same conventions of env register, argument lists will be accumulated in argl , a procedure function to be applied will be in proc , fun , procedures functions will return their answers in val , and the location to which a procedure function should return will be kept in continue . In general, the compiler translates a source program into an object program that performs essentially the same register operations as would the interpreter in evaluating the same source program. This description suggests a strategy for implementing a rudimentary compiler: We traverse the expression component in the same way the interpreter does. When we encounter a register instruction that the interpreter would perform in evaluating the expression, component, we do not execute the instruction but instead accumulate it into a sequence. The resulting sequence of instructions will be the object code.",
    "token_count": 248,
    "source_files": [
      "section5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": "Computing with Register Machines",
    "subsection": "Compilation",
    "chunk_id": "chapter5_chunks_Compilation_4",
    "chunk_index": 4,
    "content": "Observe the an expression for example, a component for example, (f 84 96) it f(96, 22) it performs the work of classifying the expression component (discovering that this is a procedure function application) and testing for the end of the operand list (discovering that there are two operands). list of argument expressions (discovering that there are two argument expressions). With a compiler, the expression component is analyzed only once, when the instruction sequence is generated at compile time. The object code produced by the compiler contains only the instructions that evaluate the operator and the two operands, function expression and the two argument expressions, assemble the argument list, and apply the procedure (in proc ) function (in fun ) to the arguments (in argl ). This is the same kind of optimization we implemented in the . But there are further opportunities to gain efficiency in compiled code. As the interpreter runs, it follows a process that must be applicable to any expression component in the language. In contrast, a given segment of compiled code is meant to execute some particular expression. component. This can make a big difference, for example in the use of the stack to save registers. When the interpreter evaluates an expression, a component, it must be prepared for any contingency. Before evaluating a subexpression, subcomponent, the interpreter saves all registers that will be needed later, because the subexpression subcomponent might require an arbitrary evaluation.",
    "token_count": 290,
    "source_files": [
      "section5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": "Computing with Register Machines",
    "subsection": "Compilation",
    "chunk_id": "chapter5_chunks_Compilation_5",
    "chunk_index": 5,
    "content": "A compiler, on the other hand, can exploit the structure of the particular expression component it is processing to generate code that avoids unnecessary stack operations. As a case in point, consider the combination (f 84 96) . application f(96, 22) . Before the interpreter evaluates the operator of the combination, function expression of the application, it prepares for this evaluation by saving the registers containing the operands argument expressions and the environment, whose values will be needed later. The interpreter then evaluates the operator function expression to obtain the result in val , restores the saved registers, and finally moves the result from val to proc . fun . However, in the particular expression we are dealing with, the operator function expression is the symbol name f , whose evaluation is accomplished by the machine operation lookup-variable-value , lookup_symbol_value , which does not alter any registers. The compiler that we implement in this section will take advantage of this fact and generate code that evaluates the operator function expression using the instruction (assign proc (op lookup-variable-value) (const f) (reg env)) assign(\"fun\", list(op(\"lookup_symbol_value\"), constant(\"f\"), reg(\"env\"))) where the argument to lookup_symbol_value is extracted at compile time from the parser's representation of f(96, 22) . This code not only avoids the unnecessary saves and restores but also assigns the value of the lookup directly to proc , fun , whereas the interpreter would obtain the result in val and then move this to proc .",
    "token_count": 300,
    "source_files": [
      "section5.xml"
    ]
  },
  {
    "chapter_file": "chapter5_chunks.json",
    "section": "Computing with Register Machines",
    "subsection": "Compilation",
    "chunk_id": "chapter5_chunks_Compilation_6",
    "chunk_index": 6,
    "content": "fun . A compiler can also optimize access to the environment. Having analyzed the code, the compiler can in many cases know in which frame a particular variable the value of a particular name will be located and access that frame directly, rather than performing the lookup-variable-value lookup_@symbol_@value search. We will discuss how to implement such variable access lexical addressing in section . Until then, however, we will focus on the kind of register and stack optimizations described above. There are many other optimizations that can be performed by a compiler, such as coding primitive operations in line instead of using a general apply mechanism (see exercise ); but we will not emphasize these here. Our main goal in this section is to illustrate the compilation process in a simplified (but still interesting) context.",
    "token_count": 155,
    "source_files": [
      "section5.xml"
    ]
  }
]