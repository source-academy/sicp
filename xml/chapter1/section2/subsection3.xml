<SUBSECTION>
  
  <NAME>Orders of Growth</NAME>

  <LABEL NAME="sec:orders-of-growth"/>
  <INDEX>order of growth<OPEN/></INDEX>

  <TEXT>
    The previous examples illustrate that processes can differ
    considerably in the rates at which they consume computational
    resources.  One convenient way to describe this difference is to use
    the notion of 
    <INDEX>process<SUBINDEX>order of growth of</SUBINDEX></INDEX>
    <EM>order of growth</EM> to obtain a gross measure of the
    <INDEX>process<SUBINDEX>resources required by</SUBINDEX></INDEX>
    resources required by a process as the inputs become larger.
  </TEXT>

  <TEXT>
    Let <LATEXINLINE>$n$</LATEXINLINE> be a parameter that measures the size of
    the problem,  and let <LATEXINLINE>$R(n)$</LATEXINLINE> be the amount 
    of resources the process requires for a problem of size
    <LATEXINLINE>$n$</LATEXINLINE>.  In our previous examples we took 
    <LATEXINLINE>$n$</LATEXINLINE> to be the number for which a given
    function is to be computed, but there are other possibilities.
    For instance, if our goal is to compute an approximation to the
    square root of a number, we might take 
    <LATEXINLINE>$n$</LATEXINLINE> to be the number of digits accuracy required.
    For matrix multiplication we might take <LATEXINLINE>$n$</LATEXINLINE> to
    be the number of rows in the matrices. In general there are a number of
    properties of the problem with respect to which it will be desirable to
    analyze a given process. Similarly, <LATEXINLINE>$R(n)$</LATEXINLINE>
    might measure the number of internal storage registers used, the
    number of elementary machine operations performed, and so on.  In
    computers that do only a fixed number of operations at a time, the
    time required will be proportional to the number of elementary machine
    operations performed.
  </TEXT>

  <TEXT>
    We say that <LATEXINLINE>$R(n)$</LATEXINLINE> has order of growth
    <INDEX><ORDER>0t</ORDER><LATEXINLINE>$\theta(f(n))$</LATEXINLINE> (theta of <LATEXINLINE>$f(n)$</LATEXINLINE>)</INDEX>
    <INDEX><ORDER>theta</ORDER><LATEXINLINE>$\theta(f(n))$</LATEXINLINE> (theta of <LATEXINLINE>$f(n)$</LATEXINLINE>)</INDEX>
    <INDEX>order notation</INDEX>
    <LATEXINLINE>$\Theta(f(n))$</LATEXINLINE>, written
    <LATEXINLINE>$R(n)=\Theta(f(n))$</LATEXINLINE> (pronounced
    <QUOTE>theta of <LATEXINLINE>$f(n)$</LATEXINLINE></QUOTE>), if there are
    positive constants <LATEXINLINE>$k_1$</LATEXINLINE> and
    <LATEXINLINE>$k_2$</LATEXINLINE> independent of
    <LATEXINLINE>$n$</LATEXINLINE> such that
    <LATEX>
      \[
      \begin{array}{lllll}
      k_1\,f(n) &amp; \leq &amp; R(n) &amp; \leq &amp; k_2\,f(n)
      \end{array}
      \]
    </LATEX>
    for any sufficiently large value of <LATEXINLINE>$n$</LATEXINLINE>.
    (In other words, for large <LATEXINLINE>$n$</LATEXINLINE>, 
    the value <LATEXINLINE>$R(n)$</LATEXINLINE> is sandwiched between 
    <LATEXINLINE>$k_1f(n)$</LATEXINLINE> and
    <LATEXINLINE>$k_2f(n)$</LATEXINLINE>.)
  </TEXT>

  <TEXT>
    <INDEX>order of growth<SUBINDEX>linear recursive process</SUBINDEX></INDEX>
    <INDEX>linear recursive process<SUBINDEX>order of growth</SUBINDEX></INDEX>
    <INDEX>recursive process<SUBINDEX>linear</SUBINDEX></INDEX>
    For instance, with the linear recursive process for computing factorial
    described in section<SPACE/><REF NAME="sec:recursion-and-iteration"/> the
    number of steps grows proportionally to the input
    <LATEXINLINE>$n$</LATEXINLINE>.  Thus, the steps required for this process
    grows as <LATEXINLINE>$\Theta(n)$</LATEXINLINE>.  We also saw that the space
    required grows as <LATEXINLINE>$\Theta(n)$</LATEXINLINE>. For the 
    <INDEX>order of growth<SUBINDEX>linear iterative process</SUBINDEX></INDEX>
    <INDEX>linear iterative process<SUBINDEX>order of growth</SUBINDEX></INDEX>
    <INDEX>iterative process<SUBINDEX>linear</SUBINDEX></INDEX>
    iterative factorial, the number of steps is still
    <LATEXINLINE>$\Theta(n)$</LATEXINLINE> but the space is
    <LATEXINLINE>$\Theta(1)$</LATEXINLINE><EMDASH/>that is, 
    constant.<FOOTNOTE>These statements mask a great deal of oversimplification.
    For instance, if we count process steps as <QUOTE>machine operations</QUOTE>
    we are making the assumption that the number of machine operations needed to
    perform, say, a multiplication is independent of the size of the numbers to
    be multiplied, which is false if the numbers are sufficiently large.
    Similar remarks hold for the estimates of space.  Like the design and
    description of a process, the analysis of a process can be carried out at
    various levels of abstraction.</FOOTNOTE> 
    The 
    <INDEX>order of growth<SUBINDEX>tree-recursive process</SUBINDEX></INDEX>
    <INDEX>tree-recursive process<SUBINDEX>order of growth</SUBINDEX></INDEX>
    <INDEX>recursive process<SUBINDEX>tree</SUBINDEX></INDEX>
    tree-recursive Fibonacci computation requires
    <LATEXINLINE>$\Theta(\phi^{n})$</LATEXINLINE> steps and space 
    <LATEXINLINE>$\Theta(n)$</LATEXINLINE>, where
    <LATEXINLINE>$\phi$</LATEXINLINE> is the golden ratio described in
    section<SPACE/><REF NAME="sec:tree-recursion"/>.
  </TEXT>

  <TEXT>
    Orders of growth provide only a crude description of the behavior of a
    process.  For example, a process requiring <LATEXINLINE>$n^2$</LATEXINLINE>
    steps and a process requiring <LATEXINLINE>$1000n^2$</LATEXINLINE> steps and
    a process requiring <LATEXINLINE>$3n^2+10n+17$</LATEXINLINE> steps all have
    <LATEXINLINE>$\Theta(n^2)$</LATEXINLINE> order of growth.  On the other hand,
    order of growth provides a useful indication of how we may expect the
    behavior of the process to change as we change the size of the problem.
    For a
    <INDEX>linear growth</INDEX>
    <LATEXINLINE>$\Theta(n)$</LATEXINLINE> (linear) process, doubling the size
    will roughly double the amount of resources used.  For an 
    <INDEX>exponential growth</INDEX>
    exponential process, each increment in problem size will multiply the
    resource utilization by a constant factor.  In the remainder of
    section<SPACE/><REF NAME="sec:procedures-and-processes"/>
    we will examine two algorithms whose order of growth is 
    <INDEX>logarithmic growth</INDEX>
    logarithmic, so that doubling the problem size increases the resource
    requirement by a constant amount.
    <INDEX>order of growth<CLOSE/></INDEX>
  </TEXT>

  <EXERCISE>
    Draw the tree illustrating the process generated by the 
    <SPLITINLINE>
      <SCHEME><SCHEMEINLINE>count-change</SCHEMEINLINE> procedure
      </SCHEME>
      <JAVASCRIPT><JAVASCRIPTINLINE>count_change</JAVASCRIPTINLINE> function
      </JAVASCRIPT>
    </SPLITINLINE> 
    of section<SPACE/><REF NAME="sec:tree-recursion"/> in making change for
    11 cents.  What are the orders of growth of the space and number of steps
    used by this process as the amount to be changed increases?
    <SOLUTION>
      The tree-recursive process generated in computing
      <JAVASCRIPTINLINE>cc(11, 5)</JAVASCRIPTINLINE> is illustrated by the
      image below, due to Toby Thain, assuming that the coin values in
      <JAVASCRIPTINLINE>first_denomination</JAVASCRIPTINLINE> are
      <LATEXINLINE>$\mathbb{C}_{1} = 1$</LATEXINLINE>,
      <LATEXINLINE>$\mathbb{C}_{2} = 5$</LATEXINLINE>,
      <LATEXINLINE>$\mathbb{C}_{3} = 10$</LATEXINLINE>,
      <LATEXINLINE>$\mathbb{C}_{4} = 25$</LATEXINLINE> and
      <LATEXINLINE>$\mathbb{C}_{5} = 50$</LATEXINLINE>.

      <FIGURE src="img_javascript/ex1-14.png">
	<LABEL NAME= "ex1-14"/>
      </FIGURE>
      
      Let us consider the process for evaluating
      <JAVASCRIPTINLINE>cc(n, k)</JAVASCRIPTINLINE>, which means the amount to
      be changed is <JAVASCRIPTINLINE>n</JAVASCRIPTINLINE> and the number of
      kinds of coins is <JAVASCRIPTINLINE>k</JAVASCRIPTINLINE>. Let us assume
      the coin values are constants, not dependent on
      <JAVASCRIPTINLINE>n</JAVASCRIPTINLINE> or
      <JAVASCRIPTINLINE>k</JAVASCRIPTINLINE>.
      <P/>
      The space required for a tree-recursive process is<EMDASH/>as discussed in
      section<SPACE/><REF NAME="sec:tree-recursion"/><EMDASH/>proportional to the
      maximum depth of the tree. At each step from a parent to a child in the
      tree, either <JAVASCRIPTINLINE>n</JAVASCRIPTINLINE> strictly decreases
      (by a constant coin value) or <JAVASCRIPTINLINE>k</JAVASCRIPTINLINE>
      decreases (by 1), and leaf nodes have an amount of at most 0 or a number
      of kinds of coins of 0. Thus, every path has a length of
      <LATEXINLINE>$\Theta(n + k)$</LATEXINLINE>, which is also the order of
      growth of the space required for
      <JAVASCRIPTINLINE>cc(n, k)</JAVASCRIPTINLINE>.
      <P/>
      <!-- http://www.ysagade.nl/2015/04/12/sicp-change-growth/ -->
      Let us derive a function <LATEXINLINE>$T(n, k)$</LATEXINLINE> such that
      the time required for calculating
      <JAVASCRIPTINLINE>cc(n, k)</JAVASCRIPTINLINE> has an order of growth of
      <LATEXINLINE>$\Theta(T(n, k))$</LATEXINLINE>. The following argument is
      due to Yati Sagade, including the illustrations
      (<CITATION>Sagade 2015</CITATION>).
      Let us start with the call tree for changing some amount
      <LATEXINLINE>$n$</LATEXINLINE> with just 1 kind of coin, i.e.,
      the call tree for <JAVASCRIPTINLINE>cc(n, 1)</JAVASCRIPTINLINE>.

      <FIGURE src="img_javascript/cc_1.png">
	<LABEL>cc_1</LABEL>
      </FIGURE>
      
      We are only allowed here to use one kind of coin, with value
      <LATEXINLINE>$\mathbb{C}_{1} = 1$</LATEXINLINE>. The red nodes are
      terminal nodes that yield 0, the green node is a terminal node that
      yields 1 (corresponding to the first condition in the declaration of
      <JAVASCRIPTINLINE>cc</JAVASCRIPTINLINE>). Each nonterminal node spawns
      two calls to <JAVASCRIPTINLINE>cc</JAVASCRIPTINLINE>, one (on the left)
      with the same amount, but fewer kinds of coins, and the other (on the
      right) with the amount reduced by 1 and equal kinds of coins.
      <P/>
      Excluding the root, each level has exactly 2 nodes, and there are
      <LATEXINLINE>$n$</LATEXINLINE> such levels. This means, the number of
      <JAVASCRIPTINLINE>cc</JAVASCRIPTINLINE> calls generated by a single
      <JAVASCRIPTINLINE>cc(n, 1)</JAVASCRIPTINLINE> call (including the original
      call) is:
      <LATEX>
	\[
	T(n,1) = 2n + 1 = \Theta(n)
	\]
      </LATEX>
      Next, we will look at the call tree of
      <JAVASCRIPTINLINE>cc(n, 2)</JAVASCRIPTINLINE> 
      to calculate <LATEXINLINE>$T(n,2)$</LATEXINLINE>:

      <FIGURE src="img_javascript/cc_2.png">
	<LABEL NAME="cc_2"/>
      </FIGURE>

      Here, we are allowed to use two denominations of coins:
      <LATEXINLINE>$\mathbb{C}_{2} = 5$</LATEXINLINE>
      and <LATEXINLINE>$\mathbb{C}_{1} = 1$</LATEXINLINE>.
      <P/>
      Each black node spawns a <JAVASCRIPTINLINE>cc(m, 1)</JAVASCRIPTINLINE>
      subtree (blue), which we’ve already analyzed, and a
      <JAVASCRIPTINLINE>cc(m - 5, 2)</JAVASCRIPTINLINE> subtree. The node
      colored in red and green is a terminal node, but yields 0 if the amount
      is less than zero and 1 if the amount is exactly zero. Sagade denotes
      this final amount as <LATEXINLINE>$\epsilon$</LATEXINLINE>, which can
      be <LATEXINLINE>$\le0$</LATEXINLINE>.
      <P/>
      Excluding the root and and the last level in this tree which contains the
      red-green terminal node, there will be exactly
      <LATEXINLINE>$\big\lfloor {\frac {n} {5}} \big\rfloor$</LATEXINLINE>
      levels. Now each of these levels contains a call to
      <JAVASCRIPTINLINE>cc(m, 1)</JAVASCRIPTINLINE> (the blue nodes), each of
      which, in turn, is <LATEXINLINE>$\Theta(n)$</LATEXINLINE> in time. So each
      of these levels contains <LATEXINLINE>$T(n,1) + 1$</LATEXINLINE> calls to
      <JAVASCRIPTINLINE>cc</JAVASCRIPTINLINE>. Therefore, the total number of
      nodes (including the terminal node and the root) in the call tree for
      <JAVASCRIPTINLINE>cc(n, 2)</JAVASCRIPTINLINE> is:
      <LATEX>
	\[
	T(n,2) = \big\lfloor {\frac {n} {5} } \big\rfloor ( T(n,1) + 1) + 2 = \big\lfloor {\frac {n} {5} } \big\rfloor ( 2n + 2 ) + 2 = \Theta(n^2)
	\]
      </LATEX>
      Moving ahead, let’s take a look at the call tree of
      <JAVASCRIPTINLINE>cc(n, 3)</JAVASCRIPTINLINE>, i.e., we are now allowed
      to use three denominations of coins, the new addition being
      <LATEXINLINE>$\mathbb{C}_{3} = 10$</LATEXINLINE>:

      <FIGURE src="img_javascript/cc_3.png">
	<LABEL NAME="cc_3"/>
      </FIGURE>

      Here also, we see, similar to the previous case, that the total number of
      calls to <JAVASCRIPTINLINE>cc</JAVASCRIPTINLINE> will be
      <LATEX>
	\[
	T(n,3) = \big\lfloor {\frac {n} {10} } \big\rfloor ( T(n,2) + 1) + 2 = \big\lfloor {\frac {n} {10} } \big\rfloor \times \Theta(n^2) + 2 = \Theta(n^3)
	\]
      </LATEX>
      We can see a pattern here. For some <LATEXINLINE>$k$</LATEXINLINE>,
      <LATEXINLINE>$k \gt 1$</LATEXINLINE>, we have,
      <LATEX>
	\[
	T(n,k) = \big\lfloor {\frac {n} { \mathbb{C}_{k} } } \big\rfloor ( T(n, k-1) + 1) + 2
	\]
      </LATEX>
      Here, <LATEXINLINE>$\mathbb{C}_{k}$</LATEXINLINE> is the
      <LATEXINLINE>$k^{th}$</LATEXINLINE> coin denomination. We can expand this
      further:
      <LATEX>
	\[
	T(n,k)
	= \big\lfloor {\frac {n} { \mathbb{C}_{k} } } \big\rfloor ( T(n, k-1) + 1 ) + 2
	= \big\lfloor {\frac {n} { \mathbb{C}_{k} } } \big\rfloor
	( \big\lfloor {\frac {n} { \mathbb{C}_{k-1} }  } \big\rfloor
	(... \big\lfloor \frac {n} { \mathbb{C}_{2} } \big\rfloor (2n+1) ...)
	) + 2
	= \Theta(n^k)
	\]
      </LATEX>
      Note that the actual values of the coin denominations have no effect on
      the order of growth of this process, if we assume they are constants that
      do not depend on <JAVASCRIPTINLINE>n</JAVASCRIPTINLINE> and
      <JAVASCRIPTINLINE>k</JAVASCRIPTINLINE>.
    </SOLUTION>
  </EXERCISE>

  <EXERCISE>
    <INDEX>sine<SUBINDEX>approximation for small angle</SUBINDEX></INDEX>
    The sine of an angle (specified in radians) can be computed by making use
    of the approximation <LATEXINLINE>$\sin x\approx x$</LATEXINLINE>
    if <LATEXINLINE>$x$</LATEXINLINE> is sufficiently small, and the
    trigonometric identity 
    <LATEX>
      \[
      \begin{array}{lll}
      \sin x &amp;=&amp; 3\sin {\dfrac{x}{3}}-4\sin^3{\dfrac{x}{3}}
      \end{array}
      \]
    </LATEX>
    to reduce the size of the argument of <LATEXINLINE>$\sin$</LATEXINLINE>.
    (For purposes of this exercise an angle is considered <QUOTE>sufficiently
    small</QUOTE> if its magnitude is not greater than 0.1 radians.) These
    ideas are incorporated in the following 
    <SPLITINLINE>
      <SCHEME>procedures:</SCHEME>
      <JAVASCRIPT>functions:</JAVASCRIPT>
    </SPLITINLINE>
    <SNIPPET PAGE="44">
      <INDEX><DECLARATION>cube</DECLARATION><FRAGILE/></INDEX>
      <NAME>sine_definition</NAME>
      <EXAMPLE>sine_example</EXAMPLE>
      <REQUIRES>abs_definition</REQUIRES>
      <SCHEME>
(define (cube x) (* x x x))

(define (p x)
   (- (* 3 x) (* 4 (cube x))))

(define (sine angle)
   (if (not (&gt; (abs angle) 0.1))
       angle
       (p (sine (/ angle 3.0)))))
      </SCHEME>
      <JAVASCRIPT>
function cube(x) {
    return x * x * x;
}
function p(x) {
    return 3 * x - 4 * cube(x);
}
function sine(angle) {
    return ! (abs(angle) &gt; 0.1)
           ? angle
           : p(sine(angle / 3));
}
      </JAVASCRIPT>
    </SNIPPET>

    <SNIPPET PAGE="44" HIDE="yes">
      <EXPECTED>0.9999996062176211</EXPECTED>
      <NAME>sine_example</NAME>
      <REQUIRES>sine_definition</REQUIRES>
      <SCHEME>
(define pi 3.14159)
(sine (/ pi 2))
      </SCHEME>
      <JAVASCRIPT>
sine(math_PI / 2);
      </JAVASCRIPT>
    </SNIPPET>

    <OL>
      <LI>How many times is the
      <SPLITINLINE>
	<SCHEME>procedure</SCHEME>
	<JAVASCRIPT>function</JAVASCRIPT>
      </SPLITINLINE>
      <SCHEMEINLINE>p</SCHEMEINLINE> 
      applied when
      <SPLITINLINE>
	<SCHEME><SCHEMEINLINE>(sine 12.15)</SCHEMEINLINE></SCHEME>
	<JAVASCRIPT><JAVASCRIPTINLINE>sine(12.15)</JAVASCRIPTINLINE></JAVASCRIPT>
      </SPLITINLINE>
      is evaluated?
      </LI>
      <LI>
        What is the order of growth in space and number of steps (as a function
	of<SPACE/><LATEXINLINE>$a$</LATEXINLINE>) used by the process generated
	by the <SCHEMEINLINE>sine</SCHEMEINLINE>
        <SPLITINLINE>
	  <SCHEME>procedure</SCHEME>
	  <JAVASCRIPT>function</JAVASCRIPT>
	</SPLITINLINE>
	when
	<SPLITINLINE>
	  <SCHEME><SCHEMEINLINE>(sine a)</SCHEMEINLINE></SCHEME>
	  <JAVASCRIPT><JAVASCRIPTINLINE>sine(a)</JAVASCRIPTINLINE></JAVASCRIPT>
	</SPLITINLINE>
	is evaluated?
      </LI>
    </OL>
    <SOLUTION>
      <TEXT>
	<OL>
	  <LI> The function <JAVASCRIPTINLINE>p</JAVASCRIPTINLINE>
	  will call itself recursively as long as the angle value is greater
	  than 0.1. There will be altogether 5 calls of
	  <JAVASCRIPTINLINE>p</JAVASCRIPTINLINE>, with arguments 12.15, 4.05,
	  1.35, 0.45, 0.15 and 0.05.
	  </LI>
	  <LI>
	    The function <JAVASCRIPTINLINE>sine</JAVASCRIPTINLINE> gives
	    rise to a recursive process. In each recursive call, the
	    <JAVASCRIPTINLINE>angle</JAVASCRIPTINLINE> is divided by 3
	    until its absolute value is smaller than 0.1. 
	    Thus the number of steps and the space required has an order
	    of growth of $O(\log a)$. Note that the base of the logarithm
	    is immaterial for the order of growth because the logarithms
	    of different bases differ only by a constant factor.
	  </LI>
	</OL>
      </TEXT>
    </SOLUTION>
  </EXERCISE>

</SUBSECTION>
