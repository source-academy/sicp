      <SUBSECTION>
        
        <NAME>Orders of Growth</NAME>

        <LABEL NAME="sec:orders-of-growth"/>
        <INDEX>order of growth|(</INDEX>

        <TEXT>
          The previous examples illustrate that processes can differ
          considerably in the rates at which they consume computational
          resources.  One convenient way to describe this difference is to use
          the notion of 
          <INDEX>process<SUBINDEX>order of growth of</SUBINDEX></INDEX>
          <EM>order of growth</EM> to obtain a gross measure of the
          <INDEX>process<SUBINDEX>resources required by</SUBINDEX></INDEX>
          resources required by a process as the inputs become larger.
        </TEXT>

        <TEXT>
          Let <LATEXINLINE>$n$</LATEXINLINE> be a parameter that measures the size of the problem, 
          and let <LATEXINLINE>$R$</LATEXINLINE>(<LATEXINLINE>$n$</LATEXINLINE>) be the amount 
          of resources the process requires for a problem
          of size <LATEXINLINE>$n$</LATEXINLINE>.  In our previous examples we took 
          <LATEXINLINE>$n$</LATEXINLINE> to be the number
          for which a given function is to be computed, but there are other
          possibilities.  For instance, if our goal is to compute an
          approximation to the square root of a number, we might take 
          <LATEXINLINE>$n$</LATEXINLINE> to be
          the number of digits accuracy required.  For matrix multiplication we
          might take <LATEXINLINE>$n$</LATEXINLINE> to be the number of rows in the matrices. 
          In general there are a number of properties of the problem with respect to which
          it will be desirable to analyze a given process. 
          Similarly, <LATEXINLINE>$R$</LATEXINLINE>(<LATEXINLINE>$n$</LATEXINLINE>)
          might measure the number of internal storage registers used, the
          number of elementary machine operations performed, and so on.  In
          computers that do only a fixed number of operations at a time, the
          time required will be proportional to the number of elementary machine
          operations performed.
        </TEXT>

        <TEXT>
          <INDEX>theta@<LATEXINLINE>$\theta(f(n))$</LATEXINLINE> (theta of <LATEXINLINE>$f(n)$</LATEXINLINE>)</INDEX>
          <INDEX>order notation</INDEX>
          We say that <LATEXINLINE>$R(n)$</LATEXINLINE> has order of growth <LATEXINLINE>$\Theta(f(n))$</LATEXINLINE>, written
          <LATEXINLINE>$R(n)=\Theta(f(n))$</LATEXINLINE> (pronounced <QUOTE>theta of <LATEXINLINE>$f(n)$</LATEXINLINE></QUOTE>), if there are
          positive constants <LATEXINLINE>$k_1$</LATEXINLINE> and <LATEXINLINE>$k_2$</LATEXINLINE> independent of <LATEXINLINE>$n$</LATEXINLINE> such that
          <LATEX>
          $k_1f(n) \leq R(n) \leq k_2f(n)$
          </LATEX>
          for any sufficiently large value of <LATEXINLINE>$n$</LATEXINLINE>.  (In other
          words, for large <LATEXINLINE>$n$</LATEXINLINE>, 
          the value <LATEXINLINE>$R(n)$</LATEXINLINE> is sandwiched between 
          <LATEXINLINE>$k_1f(n)$</LATEXINLINE>
          and <LATEXINLINE>$k_2f(n)$</LATEXINLINE>.)
        </TEXT>

        <TEXT>
          <INDEX>order of growth<SUBINDEX>linear recursive process</SUBINDEX></INDEX>
          <INDEX>linear recursive process<SUBINDEX>order of growth</SUBINDEX></INDEX>
          <INDEX>recursive process<SUBINDEX>linear</SUBINDEX></INDEX>
          For instance, with the linear recursive process for computing
          factorial described in section<SPACE/><REF NAME="sec:recursion-and-iteration"/> the
          number of steps grows proportionally to the input <LATEXINLINE>$n$</LATEXINLINE>.  Thus, the
          steps required for this process grows as <LATEXINLINE>$\Theta(n)$</LATEXINLINE>.  We also saw
          that the space required grows as <LATEXINLINE>$\Theta(n)$</LATEXINLINE>.
          For the 
          <INDEX>order of growth<SUBINDEX>linear iterative process</SUBINDEX></INDEX>
          <INDEX>linear iterative process<SUBINDEX>order of growth</SUBINDEX></INDEX>
          <INDEX>iterative process<SUBINDEX>linear</SUBINDEX></INDEX>
          iterative
          factorial, the number of steps is still <LATEXINLINE>$\Theta(n)$</LATEXINLINE> 
          but the space is
          <LATEXINLINE>$\Theta(1)$</LATEXINLINE><EMDASH/>that is, 
          constant.<FOOTNOTE>These statements mask a
            great deal of oversimplification.  For instance, if we count process
            steps as <QUOTE>machine operations</QUOTE> we are making the assumption that the
            number of machine operations needed to perform, say, a multiplication
            is independent of the size of the numbers to be multiplied, which is
            false if the numbers are sufficiently large.  Similar remarks hold for
            the estimates of space.  Like the design and description of a process,
            the analysis of a process can be carried out at various levels of
            abstraction.</FOOTNOTE> 
          The 
          <INDEX>order of growth<SUBINDEX>tree-recursive process</SUBINDEX></INDEX>
          <INDEX>tree-recursive process<SUBINDEX>order of growth</SUBINDEX></INDEX>
          <INDEX>recursive process<SUBINDEX>tree</SUBINDEX></INDEX>
          tree-recursive Fibonacci computation requires
          <LATEXINLINE>$\Theta(\phi^{n})$</LATEXINLINE> steps and space 
          <LATEXINLINE>$\Theta(n)$</LATEXINLINE>, where <LATEXINLINE>$\phi$</LATEXINLINE> is the
          golden ratio described in section<SPACE/><REF NAME="sec:tree-recursion"/>.
        </TEXT>

        <TEXT>
          Orders of growth provide only a crude description of the behavior of a
          process.  For example, a process requiring <LATEXINLINE>$n^2$</LATEXINLINE> steps and a process
          requiring <LATEXINLINE>$1000n^2$</LATEXINLINE> steps and a process requiring <LATEXINLINE>$3n^2+10n+17$</LATEXINLINE> steps
          all have <LATEXINLINE>$\Theta(n^2)$</LATEXINLINE> order of growth.  On the other hand, order of
          growth provides a useful indication of how we may expect the behavior
          of the process to change as we change the size of the problem.  For a
          <INDEX>linear growth</INDEX>
          <LATEXINLINE>$\Theta(n)$</LATEXINLINE> (linear) process, doubling the size will roughly double the amount
          of resources used.  For an 
          <INDEX>exponential growth</INDEX>
          exponential process, each increment in
          problem size will multiply the resource utilization by a constant
          factor.  In the remainder of section<SPACE/><REF NAME="sec:procedures-and-processes"/>
          we will examine two
          algorithms whose order of growth is 
          <INDEX>logarithmic growth</INDEX>
          logarithmic, so that doubling the
          problem size increases the resource requirement by a constant amount.
          <INDEX>order of growth|)</INDEX>
        </TEXT>

        <EXERCISE>
            Draw the tree illustrating the process generated by the 
            <SPLITINLINE><SCHEME><SCHEMEINLINE>count-change</SCHEMEINLINE></SCHEME>
              <JAVASCRIPT><JAVASCRIPTINLINE>count_change</JAVASCRIPTINLINE></JAVASCRIPT>
            </SPLITINLINE> 
            <SPLITINLINE><SCHEME>procedure</SCHEME><JAVASCRIPT>function</JAVASCRIPT></SPLITINLINE> 
            of section<SPACE/><REF NAME="sec:tree-recursion"/> in making
            change for 11 cents.  What are the orders of growth of the space and
            number of steps used by this process as the amount to be changed
            increases?
	    <SOLUTION>
	 The tree-recursive process generated in
	  computing <JAVASCRIPTINLINE>cc(11, 5)</JAVASCRIPTINLINE>
	  is illustrated by the image below,
	  due to Toby Thain,
	  assuming that the
	coin values in <JAVASCRIPTINLINE>first_denomination</JAVASCRIPTINLINE>
	are
	<LATEXINLINE>$\mathbb{C}_{1} = 1$</LATEXINLINE>,
	<LATEXINLINE>$\mathbb{C}_{2} = 5$</LATEXINLINE>,
	<LATEXINLINE>$\mathbb{C}_{3} = 10$</LATEXINLINE>,
	<LATEXINLINE>$\mathbb{C}_{4} = 25$</LATEXINLINE> and
	<LATEXINLINE>$\mathbb{C}_{5} = 50$</LATEXINLINE>.

	<P>
          <IMAGE src="img_javascript/ex1-14.png"/>
	</P>
	
	Let us consider the process for evaluating
	<JAVASCRIPTINLINE>cc(n, k)</JAVASCRIPTINLINE>, which
	means the amount to be changed is <JAVASCRIPTINLINE>n</JAVASCRIPTINLINE>
	and the number of kinds of coins is <JAVASCRIPTINLINE>k</JAVASCRIPTINLINE>.
	Let us assume the coin values are constants, not dependent
	on <JAVASCRIPTINLINE>n</JAVASCRIPTINLINE> or
	<JAVASCRIPTINLINE>k</JAVASCRIPTINLINE>.
	<P/>
	The space required for a tree-recursive process is<EMDASH/>as
	discussed in
	section<SPACE/><REF NAME="sec:tree-recursion"/><EMDASH/>proportional
	to the maximum depth of the tree. At each step from a parent to a
	child in the tree, either <JAVASCRIPTINLINE>n</JAVASCRIPTINLINE>
	strictly decreases (by a constant coin value) or
	<JAVASCRIPTINLINE>k</JAVASCRIPTINLINE>
	decreases (by 1), and leaf nodes have an amount of at most 0 or
	a number of kinds of coins of 0. Thus, every path has a length
	of <LATEXINLINE>$\Theta(n + k)$</LATEXINLINE>, which is also
	the order of growth of the space required for
	<JAVASCRIPTINLINE>cc(n, k)</JAVASCRIPTINLINE>.
	<P/>
	<!-- http://www.ysagade.nl/2015/04/12/sicp-change-growth/ -->
	Let us derive a function
	<LATEXINLINE>$T(n, k)$</LATEXINLINE> such that
	the time required for calculating
	<JAVASCRIPTINLINE>cc(n, k)</JAVASCRIPTINLINE>
	has an order of growth of <LATEXINLINE>$\Theta(T(n, k))$</LATEXINLINE>.
	The following argument is due to Yati Sagade, including the
	illustrations
	(<CITATION>Sagade 2015</CITATION>).
	Let us start with the call tree for changing some amount
	<LATEXINLINE>$n$</LATEXINLINE> with
	just 1 kind of coin, i.e.,
	the call tree for 
	<JAVASCRIPTINLINE>cc(n, 1)</JAVASCRIPTINLINE>.

	<P>
        <IMAGE src="img_javascript/cc_1.png"/>
	</P>
	
	We are only allowed here to use one kind of coin,
	with value <LATEXINLINE>$\mathbb{C}_{1} = 1$</LATEXINLINE>.
	The red nodes are terminal nodes that yield 0, the green node
is a terminal node that yields 1 (corresponding to the first
condition in the declaration of <JAVASCRIPTINLINE>cc</JAVASCRIPTINLINE>).
Each nonterminal node spawns two calls to
<JAVASCRIPTINLINE>cc</JAVASCRIPTINLINE>,
one (on the left) with the same amount, but fewer kinds of coins, and
the other (on the right) with the amount reduced by 1 and equal kinds of coins.
<P/>
Excluding the root, each level has exactly 2 nodes, and there
are <span>$n$</span> such levels. This means, the number of
<JAVASCRIPTINLINE>cc</JAVASCRIPTINLINE>
calls
generated by a single
<JAVASCRIPTINLINE>cc(n, 1)</JAVASCRIPTINLINE> 
call (including the original call) is:
<LATEX>
\[
T(n,1) = 2n + 1 = \Theta(n)
\]
</LATEX>
Next, we will look at the call tree of
<JAVASCRIPTINLINE>cc(n, 2)</JAVASCRIPTINLINE> 
to calculate
<LATEXINLINE>$T(n,2)$</LATEXINLINE>:

<P>
<IMAGE src="img_javascript/cc_2.png"/>
</P>

Here, we are allowed to use two denominations of coins:
<LATEXINLINE>$\mathbb{C}_{2} = 5$</LATEXINLINE>
and <LATEXINLINE>$\mathbb{C}_{1} = 1$</LATEXINLINE>.
<P/>
Each black node spawns a
<JAVASCRIPTINLINE>cc(m, 1)</JAVASCRIPTINLINE>
subtree (blue), which we’ve already
analyzed, and a
<JAVASCRIPTINLINE>cc(m - 5, 2)</JAVASCRIPTINLINE>
subtree. The node colored in red and green is
a terminal node, but yields 0 if the amount is less than zero
and 1 if the amount is exactly zero. Sagade denotes this final
amount as <LATEXINLINE>$\epsilon$</LATEXINLINE>,
which can be <LATEXINLINE>$\le0$</LATEXINLINE>.
<P/>
Excluding the root and and the last level in this tree which contains the
red-green terminal node, there will be exactly
<LATEXINLINE>$\lfloor {\frac {n} {5}} \rfloor$</LATEXINLINE> levels.
Now each of these levels contains a call to
<JAVASCRIPTINLINE>cc(m, 1)</JAVASCRIPTINLINE> (the blue nodes),
each of which, in turn, is
<LATEXINLINE>$\Theta(n)$</LATEXINLINE>
in time. So each of these levels contains
<LATEXINLINE>$T(n,1) + 1$</LATEXINLINE>
calls to
<JAVASCRIPTINLINE>cc</JAVASCRIPTINLINE>.
Therefore, the total number of
nodes (including the terminal node and the root) in the
call tree for
<JAVASCRIPTINLINE>cc(n, 2)</JAVASCRIPTINLINE>
is:
<LATEX>
  \[
T(n,2) = \lfloor {\frac {n} {5} } \rfloor ( T(n,1) + 1) + 2 = \lfloor {\frac {n} {5} } \rfloor ( 2n + 2 ) + 2 = \Theta(n^2)
\]
</LATEX>

Moving ahead, let’s take a look at the call tree of
<JAVASCRIPTINLINE>cc(n, 3)</JAVASCRIPTINLINE>,
i.e., we are
now allowed to use three denominations of coins, the new addition being
<LATEXINLINE>$\mathbb{C}_{3} = 10$</LATEXINLINE>:

<P>
<IMAGE src="img_javascript/cc_3.png"/>
</P>

Here also, we see, similar to the previous case, that the total number of calls
to
<JAVASCRIPTINLINE>cc</JAVASCRIPTINLINE>
will be
<LATEX>
\[
T(n,3) = \lfloor {\frac {n} {10} } \rfloor ( T(n,2) + 1) + 2 = \lfloor {\frac {n} {10} } \rfloor \times \Theta(n^2) + 2 = \Theta(n^3)
\]
</LATEX>
We can see a pattern here.
For some <LATEXINLINE>$k$</LATEXINLINE>,
<LATEXINLINE>$k \gt 1$</LATEXINLINE>,
we have,
<LATEX>
\[
  T(n,k) = \lfloor {\frac {n} { \mathbb{C}_{k} } } \rfloor ( T(n, k-1) + 1) + 2
\]
</LATEX>
Here,
<LATEXINLINE>$\mathbb{C}_{k}$</LATEXINLINE>
is the
<LATEXINLINE>$k^{th}$</LATEXINLINE> coin denomination. We can
expand this further:
<LATEX>
\[
  T(n,k)
= \lfloor {\frac {n} { \mathbb{C}_{k} } } \rfloor ( T(n, k-1) + 1 ) + 2
= \lfloor {\frac {n} { \mathbb{C}_{k} } } \rfloor
( \lfloor {\frac {n} { \mathbb{C}_{k-1} }  } \rfloor
(... \lfloor \frac {n} { \mathbb{C}_{2} } \rfloor (2n+1) ...)
) + 2
= \Theta(n^k)
\]
</LATEX>
Note that the actual
values of the coin denominations have no effect on the order of growth of this
process, if we assume they are constants that do not depend on
<JAVASCRIPTINLINE>n</JAVASCRIPTINLINE> and
<JAVASCRIPTINLINE>k</JAVASCRIPTINLINE>.
	    </SOLUTION>
        </EXERCISE>

        <EXERCISE>
          <INDEX>sine<SUBINDEX>approximation for small angle</SUBINDEX></INDEX>
          The sine of an angle (specified in
          radians) can be computed by making use of the approximation
          <LATEXINLINE>$\sin x\approx x$</LATEXINLINE>
          if <LATEXINLINE>$x$</LATEXINLINE> is
          sufficiently small, and the trigonometric identity 
          <LATEX>
              $\sin x=3\sin {\frac{x}{3}}-4\sin^3{\frac{x}{3}}$
          </LATEX>
          to reduce the size of the argument of <LATEXINLINE>$\sin$</LATEXINLINE>.  (For
          purposes of this exercise an angle is considered <QUOTE>sufficiently
            small</QUOTE> if its magnitude is not greater than 0.1 radians.) These
          ideas are incorporated in the following 
          <SPLITINLINE><SCHEME>procedures</SCHEME><JAVASCRIPT>functions</JAVASCRIPT></SPLITINLINE>:
          <!-- \indcode*{cube} -->
          <SNIPPET PAGE="44">
            <NAME>sine_definition</NAME>
            <EXAMPLE>sine_example</EXAMPLE>
            <REQUIRES>abs_definition</REQUIRES>
            <SCHEME>
(define (cube x) (* x x x))

(define (p x)
   (- (* 3 x) (* 4 (cube x))))

(define (sine angle)
   (if (not (&gt; (abs angle) 0.1))
       angle
       (p (sine (/ angle 3.0)))))
            </SCHEME>
            <JAVASCRIPT>
function cube(x) {
    return x * x * x;
}
function p(x) {
    return 3 * x - 4 * cube(x);
}
function sine(angle) {
    return !(abs(angle) &gt; 0.1)
           ? angle
           : p(sine(angle / 3.0));
}
            </JAVASCRIPT>
          </SNIPPET>

        <SNIPPET PAGE="44" HIDE="yes">
          <NAME>sine_example</NAME>
          <REQUIRES>sine_definition</REQUIRES>
          <SCHEME>
(define pi 3.14159)
(sine (/ pi 2))
          </SCHEME>
          <JAVASCRIPT>
sine(math_PI / 2);
          </JAVASCRIPT>
        </SNIPPET>

        <OL>
          <LI>How many times is the
	  <SPLITINLINE><SCHEME>procedure</SCHEME><JAVASCRIPT>function</JAVASCRIPT></SPLITINLINE> <SCHEMEINLINE>p</SCHEMEINLINE> 
          applied when
	  <SPLITINLINE>
	    <SCHEME><SCHEMEINLINE>(sine 12.15)</SCHEMEINLINE></SCHEME>
	    <JAVASCRIPT><JAVASCRIPTINLINE>sine(12.15)</JAVASCRIPTINLINE></JAVASCRIPT>
	  </SPLITINLINE>
	  is evaluated?
        </LI>
        <LI>
        What is the order of growth in space and number of steps (as a
        function of<SPACE/><LATEXINLINE>$a$</LATEXINLINE>) used by the process generated by the <SCHEMEINLINE>sine</SCHEMEINLINE>
        <SPLITINLINE><SCHEME>procedure</SCHEME><JAVASCRIPT>function</JAVASCRIPT></SPLITINLINE>
	when
	<SPLITINLINE>
	  <SCHEME><SCHEMEINLINE>(sine a)</SCHEMEINLINE></SCHEME>
	  <JAVASCRIPT><JAVASCRIPTINLINE>sine(a)</JAVASCRIPTINLINE></JAVASCRIPT>
	</SPLITINLINE>
	is evaluated?
        </LI>
        </OL>
    <SOLUTION>
    <TEXT>
      <OL>
	<LI> The function <JAVASCRIPTINLINE>p</JAVASCRIPTINLINE>
	will call itself recursively
	as long as the angle value is greater than 0.1. There will be 
	altogether 5 calls of <JAVASCRIPTINLINE>p</JAVASCRIPTINLINE>,
	with arguments 12.15, 4.05, 1.35, 0.45, 0.15 and 0.05.
	</LI>
	<LI>
	  The function <JAVASCRIPTINLINE>sine</JAVASCRIPTINLINE> gives
	  rise to a recursive process. In each recursive call, the
	  <JAVASCRIPTINLINE>angle</JAVASCRIPTINLINE> is divided by 3
	  until its absolute value is smaller than 0.1. 
	  Thus the number of steps and the space required has an order
	  of growth of $O(\log a)$. Note that the base of the logarithm
	  is immaterial for the order of growth because the logarithms
	  of different bases differ only by a constant factor.
	</LI>
      </OL>
    </TEXT>
  </SOLUTION>
        </EXERCISE>

      </SUBSECTION>
